{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047e1457",
   "metadata": {},
   "source": [
    "## Looking at hydrographs and event delineations from [Kincaid et al., 2020](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR027361). \n",
    "\n",
    "- ### Data publicly available here on HydroShare: https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "\n",
    "- ### This larger dataset includes the 2014-2015 discharge and nitrate data from Vaughan, M. (2017). Vermont NEWRnet stations: 2014-2015 high-frequency DOC, nitrate, and discharge data, HydroShare, http://www.hydroshare.org/resource/faac1672244c407e9c9c8644c8211fd6.\n",
    "\n",
    "- ### I downloaded on 05.02.24 and put it here in this directory /home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_partition_hysteresis\n",
    "\n",
    "- ### The raw data file has discharge (q m3s), NO3, and SRP with timestamp and event start/end times for each watershed..\n",
    "\n",
    "## I use the Kincaid 2020 events as delineated using HydRun with manual interventions.\n",
    " \n",
    " - ### Data were copied to this repo from the BREE OneDrive directory. One csv for each watershed, 2014-2018.\n",
    " - #### There was a storm (my storm #22) in the Kincaid Potash file that had an incorrect end year (7/25/2015 21:45 but was 7/25/2016 21:45). I changed the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ebda17",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "\n",
    "- [ ] use multipeak tag from Kincaid event input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc606b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 18.4\n",
      "[1] 0.12\n",
      "[1] \"number of storm events: 197\"\n",
      "             datetime q_cms  conc\n",
      "1 2014-07-27 09:00:00 0.039 0.520\n",
      "2 2014-07-27 09:15:00 0.042 0.527\n",
      "3 2014-07-27 09:30:00 0.475 0.534\n",
      "4 2014-07-27 09:45:00 0.279 0.370\n",
      "5 2014-07-27 10:00:00 0.214 0.350\n",
      "6 2014-07-27 10:15:00 0.176 0.327\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# LOAD PACKAGES #\n",
    "#################\n",
    "\n",
    "library(tidyverse)\n",
    "library(viridis)\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(glue)\n",
    "\n",
    "###################\n",
    "# SET DIRECTORIES #\n",
    "###################\n",
    "\n",
    "# Define the input and output directories\n",
    "\n",
    "# For Kincaid data, input and output in separate directory\n",
    "input_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/baseflow-rules-determinaton\"\n",
    "output_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/baseflow-rules-determinaton/output\"\n",
    "\n",
    "#################\n",
    "# SET SITE INFO #\n",
    "#################\n",
    "\n",
    "# Set site name\n",
    "Site = \"Potash\"\n",
    "\n",
    "# Set year if doing yearly\n",
    "#Year = 2015\n",
    "\n",
    "# Set constituent\n",
    "Analyte = \"NO3\"\n",
    "\n",
    "# Set catchment area based on Site\n",
    "if (Site == \"Hungerford\") {\n",
    "  Area <- 48.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  Area <- 18.4\n",
    "} else if (Site == \"Wade\") {\n",
    "  Area <- 16.7\n",
    "} else {\n",
    "  Area <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Set stormflow thresholds \n",
    "# In this case, based on Kincaid values above in table. Can use a range in other cases (see cell below).\n",
    "if (Site == \"Hungerford\") {\n",
    "  candidateSfThresh <- 0.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  candidateSfThresh <- 0.12\n",
    "} else if (Site == \"Wade\") {\n",
    "  candidateSfThresh <- 0.05\n",
    "} else {\n",
    "  candidateSfThresh <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Print the Area and SFT to check\n",
    "print(Area)\n",
    "print(candidateSfThresh)\n",
    "\n",
    "############################\n",
    "# READ IN, TIDY, JOIN DATA #\n",
    "############################\n",
    "\n",
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir, \"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Rename the 'timestamp' column to 'datetime' to conform with Millar script\n",
    "names(allInputData15Min)[names(allInputData15Min) == \"timestamp\"] <- \"datetime\"\n",
    "\n",
    "# Construct the file name for event delineation based on Site definition\n",
    "events_file <- paste(\"Events\", Site, \"2014to2018.csv\", sep = \"_\")\n",
    "\n",
    "# Read in the event delineation csv file\n",
    "customEventDel <- read.csv(file.path(input_dir, \"Event_delineations_2014-2018\", events_file)) %>%\n",
    "  # Add a storm ID\n",
    "  mutate(storm_id = glue(\"storm_{row_number()}\")) %>%\n",
    "  # Select and rename columns\n",
    "  select(storm_id, rainfall.start, start = HydRun.start, end = HydRun.end) %>%\n",
    "  # Convert start and end datetimes to POSIXct\n",
    "  mutate(start = as.POSIXct(start, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"),\n",
    "         end = as.POSIXct(end, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"))\n",
    "\n",
    "# Filter the data for just the site and for the year/time range you want\n",
    "# Memory issues if you try to process all the Kincaid 2014-2018 data at once, sometimes\n",
    "# Remove rows with missing values\n",
    "Site_input <- allInputData15Min %>%\n",
    "  filter(site == Site) %>%\n",
    "  drop_na(q_cms, NO3_mgNL) %>%\n",
    "  select(datetime, q_cms, conc = NO3_mgNL) %>%\n",
    "  mutate(datetime = as.POSIXct(datetime, format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n",
    "\n",
    "# Create a list of data frames for each storm event\n",
    "storm_data_list <- customEventDel %>%\n",
    "  rowwise() %>%\n",
    "  mutate(data = list(Site_input %>% filter(datetime >= start & datetime <= end))) %>%\n",
    "  ungroup() %>% # Ungroup to prevent grouped data issues\n",
    "  select(storm_id, data) %>%\n",
    "  group_split(storm_id) # Split by storm_id to create a list of data frames\n",
    "\n",
    "# Convert to a named list of dataframes\n",
    "storm_data_list <- setNames(lapply(storm_data_list, function(x) x$data[[1]]), customEventDel$storm_id)\n",
    "\n",
    "# Verify that the list consists of dataframes\n",
    "print(paste(\"number of storm events:\", length(storm_data_list))) # Should be 153 storms for Hungerford in Kincaid dataset\n",
    "\n",
    "# Check the structure of the first storm dataframe\n",
    "print(head(storm_data_list[[1]]))\n",
    "                                   \n",
    "eventInputs = storm_data_list\n",
    "\n",
    "# Set time same timestep as the automatic RDF\n",
    "timestep_min = 15\n",
    "                                   \n",
    "#####################\n",
    "# SET OUTPUT NAMING #\n",
    "#####################\n",
    "\n",
    "# Specify constituent in data set name\n",
    "dataSetName = paste(Site,\"_\",Analyte,\"_\",\"2014-2018\", sep=\"\")\n",
    "\n",
    "# Chose constitution for plot axes labels (NO3, TOC, or turbidity)\n",
    "constit <- Analyte\n",
    "\n",
    "Site_input$datetime <- as.POSIXct(Site_input$datetime,format(\"%Y-%m-%d %H:%M:%S\"),tz=\"EST\")\n",
    "\n",
    "# Rescale the data\n",
    "Site_input <- Site_input %>% \n",
    "  mutate(rescaled_conc = ((conc-min(conc))/(max(conc)-min(conc))*max(q_cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39660668",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Invalid input: time_trans works with objects of class POSIXct only\n",
     "output_type": "error",
     "traceback": [
      "Error: Invalid input: time_trans works with objects of class POSIXct only\nTraceback:\n",
      "1. print(hydrograph_plot)",
      "2. print.ggplot(hydrograph_plot)",
      "3. ggplot_build(x)",
      "4. ggplot_build.ggplot(x)",
      "5. lapply(data, scales_transform_df, scales = scales)",
      "6. FUN(X[[i]], ...)",
      "7. unlist(lapply(scale_list, function(s) s$transform_df(df = df)), \n .     recursive = FALSE)",
      "8. lapply(scale_list, function(s) s$transform_df(df = df))",
      "9. FUN(X[[i]], ...)",
      "10. s$transform_df(df = df)",
      "11. transform_df(..., self = self)",
      "12. lapply(df[aesthetics], self$transform)",
      "13. FUN(X[[i]], ...)",
      "14. transform(..., self = self)",
      "15. ggproto_parent(ScaleContinuous, self)$transform(x)",
      "16. transform(..., self = self)",
      "17. self$trans$transform(x)",
      "18. stop(\"Invalid input: time_trans works with objects of class \", \n  .     \"POSIXct only\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# PLOT THE HYDROGRAPH #\n",
    "#######################\n",
    "\n",
    "hydrograph_plot <- ggplot() +\n",
    "  geom_line(data = allInputData15Min, aes(x = datetime, y = q_cms, color = \"Hydrograph\")) +\n",
    "  theme_minimal() +\n",
    "  labs(title = paste(Site, \"Brook event hydrographs\", sep = \" \"),\n",
    "       x = \"Datetime\",\n",
    "       y = \"Discharge (cms)\",\n",
    "       color = \"Data Type\") +\n",
    "  scale_x_datetime(date_labels = \"%Y-%m-%d %H:%M\", date_breaks = \"1 year\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n",
    "  theme(strip.text = element_text(size = 8)) +\n",
    "  scale_color_manual(values = c(\"Hydrograph\" = \"blue\")) \n",
    "\n",
    "# Print the modified plot\n",
    "print(hydrograph_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609eaca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
