{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b70239a8",
   "metadata": {},
   "source": [
    "## In this R notebook I use Millar et al's workflow for automatic event delineation/hysteresis index calcs using the s::can and discharge data from [Kincaid et al., 2020](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR027361). \n",
    "\n",
    "## Here I adjust the Millar workflow to accept manual event delineations input and calculate event water yields.\n",
    "\n",
    "- ### Data publicly available here on HydroShare: https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "\n",
    "- ### This larger dataset includes the 2014-2015 discharge and nitrate data from Vaughan, M. (2017). Vermont NEWRnet stations: 2014-2015 high-frequency DOC, nitrate, and discharge data, HydroShare, http://www.hydroshare.org/resource/faac1672244c407e9c9c8644c8211fd6.\n",
    "\n",
    "- ### Note that there is a Hungerford data gap in 2016 to adjust this code for\n",
    "\n",
    "- ### I downloaded on 05.02.24 and put it here in this directory /home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_partition_hysteresis\n",
    "\n",
    "- ### The raw data file has discharge (q m3s), NO3, and SRP with timestamp and event start/end times for each watershed. The Millar code takes just timestamp, q, and C input csvs so I separate this raw data file into just those parameters for each site over the entire time period (>400 events from 2014 to 2018, no winter events).\n",
    "\n",
    "## I use the Kincaid 2020 events as delineated using HydRun with manual interventions.\n",
    " \n",
    " - ### Data were copied to this repo from the BREE OneDrive directory. One csv for each watershed, 2014-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abb6684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 48.1\n",
      "[1] 0.1\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# LOAD PACKAGES #\n",
    "#################\n",
    "\n",
    "library(tidyverse)\n",
    "library(viridis)\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(glue)\n",
    "\n",
    "###################\n",
    "# SET DIRECTORIES #\n",
    "###################\n",
    "\n",
    "# Define the input and output directories\n",
    "\n",
    "# For Kincaid data, input and output in separate directory\n",
    "input_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/kincaid2020_hydroshare/\"\n",
    "output_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/kincaid2020_hydroshare/output/\"\n",
    "\n",
    "# functions script in main millar directory\n",
    "millar_input_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/\"\n",
    "\n",
    "#####################\n",
    "# READ IN FUNCTIONS #\n",
    "#####################\n",
    "\n",
    "# 2024-07-08 MED note: I made a new version of the Millar functions script with my modifications\n",
    "source(file.path(input_dir,\"cQ_functions_MED_custom_delineations.R\"))\n",
    "\n",
    "#################\n",
    "# SET SITE INFO #\n",
    "#################\n",
    "\n",
    "# Set site name\n",
    "Site = \"Hungerford\"\n",
    "\n",
    "# Set year if doing yearly\n",
    "#Year = 2015\n",
    "\n",
    "# Set constituent\n",
    "Analyte = \"NO3\"\n",
    "\n",
    "# Set catchment area based on Site\n",
    "if (Site == \"Hungerford\") {\n",
    "  Area <- 48.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  Area <- 18.4\n",
    "} else if (Site == \"Wade\") {\n",
    "  Area <- 16.7\n",
    "} else {\n",
    "  Area <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Set stormflow thresholds \n",
    "# In this case, based on Kincaid values above in table. Can use a range in other cases (see cell below).\n",
    "if (Site == \"Hungerford\") {\n",
    "  candidateSfThresh <- 0.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  candidateSfThresh <- 0.12\n",
    "} else if (Site == \"Wade\") {\n",
    "  candidateSfThresh <- 0.05\n",
    "} else {\n",
    "  candidateSfThresh <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Print the Area and SFT to check\n",
    "print(Area)\n",
    "print(candidateSfThresh)\n",
    "\n",
    "#########################\n",
    "# READ IN AND TIDY DATA #\n",
    "#########################\n",
    "\n",
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir,\"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Rename the 'timestamp' column to 'datetime' to conform with Millar script\n",
    "names(allInputData15Min)[names(allInputData15Min) == \"timestamp\"] <- \"datetime\"\n",
    "\n",
    "# Construct the file name for event delineation based on Site definition\n",
    "events_file <- paste(\"Events\", Site, \"2014to2018.csv\", sep = \"_\")\n",
    "\n",
    "# Read in the event delineation csv file\n",
    "customEventDel <- read.csv(file.path(input_dir, \"Event_delineations_2014-2018\", events_file)) %>%\n",
    "  # Add a storm ID\n",
    "  mutate(start_id = glue(\"storm_{row_number()}\")) %>%\n",
    "  # Select and rename columns\n",
    "  select(start_id, rainfall.start, start = HydRun.start, end = HydRun.end) %>%\n",
    "  # Reclassify event start and end datetimes\n",
    "  mutate(across(c(start, end), ~ as.POSIXct(.x, format = \"%m/%d/%Y %H:%M\", tz = \"EST\")))\n",
    "\n",
    "# Filter the data for just the site and for the year/time range you want\n",
    "# Memory issues if you try to process all the Kincaid 2014-2018 data at once, sometimes\n",
    "# Remove rows with missing values\n",
    "Site_input <- allInputData15Min %>%\n",
    "  #filter(site == Site & year(datetime) == Year) %>%\n",
    "  filter(site == Site) %>%\n",
    "  drop_na(q_cms, NO3_mgNL) %>%\n",
    "  select(datetime, q_cms, conc = NO3_mgNL)\n",
    "\n",
    "# Specify constituent in data set name\n",
    "dataSetName = paste(Site,\"_\",Analyte,\"_\",\"2014-2018\", sep=\"\")\n",
    "\n",
    "# Chose constitution for plot axes labels (NO3, TOC, or turbidity)\n",
    "constit <- Analyte\n",
    "\n",
    "Site_input$datetime <- as.POSIXct(Site_input$datetime,format(\"%Y-%m-%d %H:%M:%S\"),tz=\"EST\")\n",
    "\n",
    "# Rescale the data\n",
    "Site_input <- Site_input %>% \n",
    "  mutate(rescaled_conc = ((conc-min(conc))/(max(conc)-min(conc))*max(q_cms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9dea6",
   "metadata": {},
   "source": [
    "## Running Millar water yield calc and HI/FI calcs with custon event start and end datetimes\n",
    "\n",
    "- ### 2024-07-15 MED note: I saved cQ_functions_MED_custom_delineations from cQ_functions_MED.R\n",
    "    - #### This version allows for water and constituent event yield calcs\n",
    "- ### I wanted the `allEventDTs` dataframe created in Millar's Function 4 (`processStormEventsWithConc`) to be supplanted with an analagous dataframe that has the following for columns:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SET RDF PARAMS #\n",
    "##################\n",
    "\n",
    "# Vector containing candidate baseflow separation filter values\n",
    "candidateFilterPara <- c(0.996,0.98) # Kincaid 2020 used 0.996 for all catchments\n",
    "\n",
    "# Vector containing candidate stormflow threshold values\n",
    "#candidateSfThresh <- c(0.098,0.1,0.12) #See cell above for Kincaid comparison use case\n",
    "\n",
    "# Vector with interpolation intervals used for calculating HI\n",
    "interp <- seq(0,1,0.01)\n",
    "\n",
    "###############################\n",
    "# RUN ANALYSIS TO GET EVENTS #\n",
    "###############################\n",
    "\n",
    "batchRun1 <- batchRunBfAndEvSepForCQ(qInputs = Site_input,\n",
    "                                     bfSepPasses = 3, # orig 3\n",
    "                                     filterParam = candidateFilterPara,\n",
    "                                     sfSmoothPasses = 4, # orig 4\n",
    "                                     sfThresh = candidateSfThresh,\n",
    "                                     cInputs = Site_input,\n",
    "                                     timeStep = 15,\n",
    "                                     minDuration = 4, # Kincaid 2020 uses 4 hrs for Hungerford\n",
    "                                     maxDuration = 200,\n",
    "                                     eventInputs = customEventDel) # MED addition\n",
    "\n",
    "eventsDataAll1 <- getAllStormEvents(batchRun = batchRun1,\n",
    "                                    timestep_min = 15)\n",
    "\n",
    "batchRunFlowsLF1 <- batchRunflowCompare(qData = Site_input,\n",
    "                                         bfSepPasses = 4, # orig 4\n",
    "                                         filterPara = candidateFilterPara,\n",
    "                                         sfSmoothPasses = 4) # orig 4\n",
    "\n",
    "eventsData1 <- stormEventCalcs(batchRun = batchRun1,\n",
    "                               timestep_min = 15)\n",
    "\n",
    "eventsData1$filter_para <- as.numeric(eventsData1$filter_para)\n",
    "\n",
    "# Add water yield column (in mm) using catchment area\n",
    "eventsData1 <- eventsData1 %>%\n",
    "  mutate(\n",
    "    water_yield_mm = tot_q_m3 / (Area * 10^6) * 1000,\n",
    "  )\n",
    "\n",
    "# Add constituent yield column (in mm) using catchment area\n",
    "eventsData1 <- eventsData1 %>%\n",
    "  mutate(\n",
    "    constit_yield_mm = (tot_constit_mgN) / (Area * 10^6),\n",
    "  )\n",
    "\n",
    "stormCounts1 <- stormCounts(batchRun1)\n",
    "\n",
    "# Not dealing with HI calc in this workflow\n",
    "#hysteresisData1 <- getHysteresisIndices(batchRun = batchRun1,\n",
    "                                        #xForInterp = interp,\n",
    "                                        #eventsData = eventsData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa10067",
   "metadata": {},
   "outputs": [],
   "source": [
    "flowData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde22350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
