{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5986415b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/millieginty/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘gridGraphics’, ‘yulab.utils’, ‘plyr’, ‘lmodel2’, ‘reshape2’, ‘ggplotify’, ‘ggnewscale’, ‘patchwork’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages('foqat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84b6aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Written by Matthew CH Vaughan\n",
    "# edited/adapted by Erin Seybold on 3/16/18\n",
    "# edited by SB, SS on 02292024\n",
    "# editied by Megan Duffy on 05/28/24\n",
    "\n",
    "library(ggplot2)\n",
    "library(\"tidyverse\")\n",
    "library(\"lubridate\")\n",
    "library(\"foqat\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------  \n",
    "# -------------------------------------------------------------------------  \n",
    "# ------------------------------------- WADE ------------------------------  \n",
    "# User inputs -------------------------------------------------------------\n",
    "\n",
    "#setwd(\"/Users/mat/OneDrive - University of Vermont/Watershed Data/Streams/02_site_data/discharge\") # for MAC\n",
    "# setwd(\"/Users/dustinkincaid/OneDrive - University of Vermont/Watershed Data/Streams/02_site_data/discharge\")\n",
    "# Import data\n",
    "\n",
    "# Import data\n",
    "setwd(\"/home/millieginty/Documents/git-repos/cQ_analysis/cond-hydrograph-separation/newrnet/data/\")\n",
    "\n",
    "#### - edited by SB and SS 02292024\n",
    "\n",
    "source(\"AquariusR/aquariusHelperFunctions.R\", chdir = T)\n",
    "\n",
    "aquariusLoginWithFile(\"AquariusR/aquariusLogin\")\n",
    "\n",
    "\n",
    "df1 <- getCorrectedAquariusDataSeries(\n",
    "  \"Sp Cond.SpecCond@Wade Brook\",\n",
    "  startTime = \"2022-01-01T00:00:00-05:00\",\n",
    "  endTime   = \"2022-12-31T00:00:00-05:00\")\n",
    "\n",
    "df1$timestamp <-df1$Timestamp\n",
    "\n",
    " # Export q data\n",
    "write.csv(df1, \"hungerford_2022_sC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56a6bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: jsonlite\n",
      "\n",
      "\n",
      "Attaching package: ‘jsonlite’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    flatten\n",
      "\n",
      "\n",
      "Loading required package: httr\n",
      "\n",
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file 'scripts/20160908_wade_stage_q_data.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(stage_discharge_filename)",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "df2 <- getCorrectedAquariusDataSeries(\n",
    "  \"Depth.Staff Ruler Height@Wade Brook\",\n",
    "  startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "  endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "\n",
    "df2$timestamp <-df2$Timestamp\n",
    "\n",
    "#### - edited end ---- SB and SS 02292024\n",
    "\n",
    "# \n",
    "# manual_staff_data <- read_csv(\"Wade_StaffGauge_2017-2022.csv\", col_types = cols())  %>% \n",
    "#   mutate(r_timestamp =  mdy_hm(timestamp, tz = \"Etc/GMT+4\"))\n",
    "\n",
    "\n",
    "\n",
    "manual_staff_data <- df2 # edited by SB SS\n",
    "\n",
    "\n",
    "stage_discharge_filename <- \"scripts/20160908_wade_stage_q_data.csv\" #rating curve info \n",
    "# hobo_stage_data_filename <- \"Wade_Stage_2022_COMPILED.csv\" #raw stage data - change this to file for analysis\n",
    "#staff_gauge_manual_readings <- \"Staff_gauge_readings/Wade_StaffGauge_2017-2020.csv\"\n",
    "\n",
    "hobo_stage_data_filename <- df1 # edited by SB SS\n",
    "\n",
    "dist_from_hobo_to_streambed <- 0.221716 # In meters. See excel spreadsheet for data+details on this calculation\n",
    "\n",
    "# Load data ---------------------------------------------------------------\n",
    "  # curve_data <- read.csv(stage_discharge_filename) - commented by SB SS Feb 2024\n",
    "  # sensor_data <- read.csv(hobo_stage_data_filename) - commented by SB SS Feb 2024\n",
    "#  manual_staff_data <- read.csv(staff_gauge_manual_readings)\n",
    "  \n",
    "# edited by SB SS 02292024\n",
    "  curve_data <- read.csv(stage_discharge_filename)\n",
    "  sensor_data <-df1 \n",
    "# end edit by SB SS 02292024\n",
    "\n",
    " # Adjust hobo stage to reflect distance above the streambed\n",
    "  curve_data$stage <- curve_data$hobo_stage + dist_from_hobo_to_streambed\n",
    "  \n",
    "  # for 2014-2017 - sensor_data doesn't needisd any additional processing other than the distance offset, for 2018 and 2019 see below.\n",
    "  \n",
    "  # for 2018\n",
    "  #sensor_data$hobo_stage_int <- 1.1225*sensor_data$hobo_stage + 0.164 # specific to 2018 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"WadeStage_2018_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    "  \n",
    "  # for 2019\n",
    "  #sensor_data$hobo_stage_int <- 0.9967*sensor_data$hobo_stage + 0.063 # specific to 2019 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"WadeStage_2019_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    " \n",
    "  # for 2020 data stage was corrected in aquarius using staff gauge readings\n",
    "  # sensor_data$Stage <- sensor_data$stage + dist_from_hobo_to_streambed\n",
    "  \n",
    "  # for 2020 \n",
    "  #sensor_data$hobo_stage_int <- 0.9163*sensor_data$hobo_stage + 0.1026 # specific to 2020 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"Wade_stage_manual_offset_2020\" for details on this correction (located in rating curve folder)\n",
    "\n",
    "  # for 2021 REVISED\n",
    "  #sensor_data$hobo_stage_int <- 0.876*sensor_data$hobo_stage + 0.1077 # specific to 2021 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"Wade_stage_manual_offset_2021\" for details on this correction (located in rating curve folder)\n",
    "\n",
    "  # for 2022 REVISED\n",
    "  #corrections already applied to \"Wade_Stage_2022_COMPILED.csv\" file, see file \"Wade_stage_manual_offset_2021\" for details on this correction (located in rating curve folder)\n",
    "    \n",
    "  # sensor_data$stage <- sensor_data$hobo_stage + dist_from_hobo_to_streambed # for 2014-2018 years, this is the final stage and can be renamed/line below can be commented out\n",
    "  \n",
    "  sensor_data$stage <- sensor_data$'Stage.Stage@Wade Brook' + dist_from_hobo_to_streambed # for 2014-2018 years, this is the final stage and can be renamed/line below can be commented out\n",
    "  \n",
    "  \n",
    "  \n",
    "  # Convert timestamps\n",
    " # sensor_data$r_timestamp <- as.POSIXct(strptime(sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    " # sensor_data$timestamp <- NULL\n",
    " \n",
    "  sensor_data$r_timestamp <- sensor_data$timestamp\n",
    " curve_data$r_timestamp <- as.POSIXct(strptime(curve_data$timestamp,'%m/%d/%Y %H:%M', tz = \"Etc/GMT-4\"))\n",
    " curve_data$timestamp <- NULL\n",
    "\n",
    "# manual_staff_data$r_timestamp <- as.POSIXct(strptime(manual_staff_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "# # manual_staff_data$timestamp <- NULL\n",
    " \n",
    " manual_staff_data$r_timestamp <- manual_staff_data$timestamp\n",
    " manual_staff_data$stage <- manual_staff_data$`Depth.Staff Ruler Height@Wade Brook`\n",
    " \n",
    "#manual_staff_data$stage <- manual_staff_data$Staff.level..m.\n",
    "#manual_staff_data$Staff.level..m. <- NULL\n",
    "\n",
    "# Tidy up manual_staff_data for comparison\n",
    "manual_staff_data <-\n",
    "  manual_staff_data%>% \n",
    "  mutate(r_timestamp = round_date(r_timestamp, unit = \"15 mins\")) %>% \n",
    "  select(timestamp, stage) %>% \n",
    "  mutate(r_timestamp = ymd_hms(timestamp))\n",
    "\n",
    " \n",
    "# Compare sensor-derived staget to manual stage readings ----------------------------\n",
    " # Join data\n",
    " allstage <- \n",
    "   sensor_data %>% \n",
    "   select(r_timestamp, stage) %>% \n",
    "   rename(stage_sensor = stage) %>% \n",
    "   full_join(manual_staff_data %>% \n",
    "               select(r_timestamp, stage) %>% \n",
    "               rename(stage_manual = stage) %>% \n",
    "               mutate(r_timestamp = round_date(r_timestamp, unit = \"15 mins\")))\n",
    " \n",
    " # Plot\n",
    " allstage %>% \n",
    "   ggplot(aes(x = stage_manual, y = stage_sensor)) +\n",
    "   geom_point() +\n",
    "   geom_abline(slope = 1)+\n",
    "   ylim(0,1.5)+\n",
    "   xlim(0,1.5)\n",
    " \n",
    " \n",
    "# Calculate the interpolated rating curve --------------------------------------------\n",
    " # First make interpolated rating curve within measurement bounds\n",
    "  max_measured_stage <- max(curve_data$stage)\n",
    "\n",
    " # Perform the power function fit\n",
    "  fit <- nls(data = curve_data, q ~ a * stage^b,  start = list(a=1, b=1))\n",
    "  fit_coeff <- summary(fit)$coefficients\n",
    "  \n",
    "  # Pull out the coefficients\n",
    "  a <- fit_coeff[1,1]\n",
    "  b <- fit_coeff[2,1]\n",
    "  \n",
    " # Create function for curve\n",
    "  power_curve <- function(x) {a * x^b}\n",
    "  \n",
    "  sensor_data$power_q <- power_curve(sensor_data$stage)\n",
    "    \n",
    " # Find the predicted q based on measured stages and the rating curve. \n",
    "  curve_data$predicted_q <- predict(fit)\n",
    "\n",
    " # Plot to check\n",
    "  p <- ggplot(data = curve_data)\n",
    "  p <- p+ geom_point(aes(x = stage, y = q, shape = type, color = r_timestamp), size = 3)\n",
    "  p <- p+ stat_function(fun = power_curve, color = \"black\", size = 1.5)\n",
    "  p\n",
    "\n",
    "# Calculate the extrapolated rating curve ---------------------------------\n",
    "  # See survey notes for where these values came from. took averages where appropriate\n",
    "  inner_width <- 7.05\n",
    "  top_lip <- 0.2275\n",
    "  culvert_diam <- inner_width + top_lip\n",
    "  culvert_radius <- culvert_diam / 2\n",
    "  berm_height <- 1.234 # from bottom to where the currogated circular culvert begins.\n",
    "  \n",
    "  # Function to find the wetted area of the culvert above the berm\n",
    "    A_wet <- function(stage, culvert_radius = 3.63875, berm_height = 1.234, inner_width = 7.05) {\n",
    "      # Create empty result vector to populate\n",
    "      result <- numeric(length(stage))\n",
    "      # Start for loop to go through each element of stage.\n",
    "      for (i in 1:length(stage)) {\n",
    "      # See if stage is above berm height\n",
    "      if ((stage[i] - berm_height) > 0) {\n",
    "        # If it is, then find the distance above berm height (y)\n",
    "           y <- stage[i] - berm_height\n",
    "           # And calculate the wetted area below berm heigh (simple rectangle)\n",
    "           A_below_berm <- inner_width * berm_height\n",
    "      # If it's not...\n",
    "      } else { \n",
    "        # Set the distance above the berm to zero\n",
    "             y <- 0\n",
    "        # And calculate the are below based on stage (rectangular area depends on how high the stage is)\n",
    "             A_below_berm <- inner_width * stage[i]\n",
    "      } # End else statement\n",
    "      \n",
    "     # Now calculate area above berm if there is any (will be 0 if stage is below berm)\n",
    "      A_sector <- culvert_radius^2 * (pi - 2*asin(y / culvert_radius)) / 2\n",
    "      A_triangle <- y * sqrt(culvert_radius^2 - y^2)\n",
    "      semi_circ <- (1/2) * pi * culvert_radius^2\n",
    "      A_above_berm <- semi_circ - (A_sector - A_triangle)\n",
    "      \n",
    "      # Add them together for the result.\n",
    "      result[i] <- A_below_berm + A_above_berm\n",
    "      } # End for loop     \n",
    "      \n",
    "      # Return the result\n",
    "      return(result)\n",
    "    } # End function\n",
    "    \n",
    "  # Function to find hydraulic radius (wetted perimeter)\n",
    "    R_wet <- function(stage, culvert_raius = 3.63875, berm_height = 1.234, inner_width = 7.05, top_lip = 0.2275) {\n",
    "      # Create empty result vector to populate\n",
    "      result <- numeric(length(stage))\n",
    "      # Start for loop to go through each element of stage.\n",
    "      for (i in 1:length(stage)) {\n",
    "      # See if stage is above berm height\n",
    "      if ((stage[i] - berm_height) > 0) {\n",
    "        # If it is, then find the distance above berm height (y)\n",
    "        y <- stage[i] - berm_height\n",
    "        # And calculate the wetted perimeter below berm heigh (simple rectangle)\n",
    "        R_below_berm <- inner_width + (2*berm_height)\n",
    "        # If it's not...\n",
    "      } else { \n",
    "        # Set y to zero\n",
    "        y <- 0\n",
    "        # Calculate wetted perimeter based on stage\n",
    "        R_below_berm <- inner_width + (2*stage[i])\n",
    "        # Set the top_lip dimension to zero\n",
    "        top_lip <- 0\n",
    "      }\n",
    "      \n",
    "      # Now calculate wetted perimeter above berm if there is any\n",
    "      R_above_berm <- (2*top_lip) + culvert_radius * asin(y / culvert_radius)\n",
    "      # Add them together for result\n",
    "      result[i] <- R_below_berm + R_above_berm\n",
    "      } # End for loop\n",
    "      \n",
    "      return(result)\n",
    "    } # End function\n",
    "    \n",
    "    # Calculate the wetted areas and radii of the sensor and curve data measurements\n",
    "  curve_data$radius <- R_wet(curve_data$stage)\n",
    "  sensor_data$radius <- R_wet(sensor_data$stage)\n",
    "  \n",
    "  curve_data$area <- A_wet(curve_data$stage)\n",
    "  sensor_data$area <- A_wet(sensor_data$stage)\n",
    "    \n",
    "  # Determeine whether the q measurement is interpolated or extrapolated based on max stage/discharge pair\n",
    "  sensor_data[which(sensor_data$stage <= max_measured_stage), \"int_or_ext\"] <- \"interpolated\"\n",
    "  sensor_data[which(sensor_data$stage > max_measured_stage), \"int_or_ext\"] <- \"extrapolated\"\n",
    "  \n",
    "  # Slope across reach calculated by Ryan\n",
    "  slope <- 0.0244\n",
    "  \n",
    "  curve_data$back_calc_n <- curve_data$area * curve_data$radius^(2/3) * sqrt(slope) / curve_data$q\n",
    "  \n",
    "  n_rough <- 1.355\n",
    "  \n",
    "  sensor_data$mannings_q <- (1 / n_rough) * sensor_data$area * sensor_data$radius ^ (2/3) * sqrt(slope)\n",
    "  \n",
    "# Combine two methods to make best curve ----------------------------------\n",
    "\n",
    " break_point <- max_measured_stage\n",
    "  \n",
    " int <- sensor_data$stage <= break_point\n",
    " ext <- sensor_data$stage > break_point\n",
    " \n",
    "  max(sensor_data$power_q[int])\n",
    "  min(sensor_data$mannings_q[ext])\n",
    " \n",
    " sensor_data$best_q <- NA\n",
    " sensor_data$best_q[int] <- sensor_data$power_q[int]\n",
    " # Bring manning's curve down a hair so that the transition is more continuous.\n",
    " sensor_data$best_q[ext] <- sensor_data$mannings_q[ext] - 0.8*(min(sensor_data$mannings_q[ext]) - max(sensor_data$power_q[int]))\n",
    "\n",
    "  e <- ggplot(data = subset(curve_data, stage > 0.6))\n",
    "  e <- e+ geom_density(aes(x = back_calc_n))\n",
    "  e\n",
    "  \n",
    "  s <- ggplot(data = sensor_data)\n",
    "  s <- s+ geom_point(aes(x = r_timestamp, y = best_q, color = int_or_ext), size = 2)\n",
    "  s\n",
    "  \n",
    "  s <- ggplot(data = sensor_data)\n",
    "  s <- s+ geom_point(aes(x = stage, y = best_q, color = int_or_ext), size = 2)\n",
    "  s\n",
    "  \n",
    "  # Export q data\n",
    "  write.csv(sensor_data, \"wade_2023_best_q_corr_SBSS.csv\")\n",
    "\n",
    "  # -------------------------------------------------------------------------  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # ------------------------------- POTASH ----------------------------------  \n",
    "  # User inputs -------------------------------------------------------------\n",
    "  \n",
    "  # #setwd(\"/Users/erinseybold/Dropbox/R/BREE_R/NN_rating_curves\") # for MAC \n",
    "  # #2020 use wd from above-sb\n",
    "  # PB_stage_data_filename <- \"2020_Potash_Stage_corrected_sb.csv\" #raw stage data - change this to file for analysis\n",
    "  # \n",
    "  # # dist_from_hobo_to_streambed --> NO depth offset for Potash\n",
    "  # \n",
    "  # # Load data ---------------------------------------------------------------\n",
    "  # PB_sensor_data <- read.csv(PB_stage_data_filename)\n",
    "  # \n",
    "  # # Convert timestamps\n",
    "  # PB_sensor_data$r_timestamp <- as.POSIXct(strptime(PB_sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "  # PB_sensor_data$timestamp <- NULL\n",
    "  # \n",
    "  # PB_sensor_data$PB_best_q <- 3.0386*(PB_sensor_data$stage^6.5671)\n",
    "  # \n",
    "  # # Export q data\n",
    "  # write.csv(PB_sensor_data, \"potash_2020_best_q.csv\")\n",
    "  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # ----------------------------- HUNGERFORD --------------------------------  \n",
    "  # User inputs -------------------------------------------------------------\n",
    "  \n",
    "  # edited by SB and SS Feb-Mar 2024\n",
    "  \n",
    "  \n",
    "  # Import data\n",
    "  setwd(\"C:/Users/sshercha/OneDrive - University of Vermont/Desktop/discharge_new\")\n",
    "  \n",
    "  #### - edited by SB and SS 02292024\n",
    "  \n",
    "  source(\"AquariusR/aquariusHelperFunctions.R\", chdir = T)\n",
    "  \n",
    "  aquariusLoginWithFile(\"AquariusR/aquariusLogin\")\n",
    "  \n",
    "  \n",
    "  df1 <- getCorrectedAquariusDataSeries(\n",
    "    \"Stage.StagemHOBO@Hungerford Brook\",\n",
    "    startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "    endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "  \n",
    "  df1$timestamp <-df1$Timestamp\n",
    "  \n",
    "  df2 <- getCorrectedAquariusDataSeries(\n",
    "    \"Stage.RelDepth@Hungerford Brook\",\n",
    "    startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "    endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "  \n",
    "  df2$timestamp <-df2$Timestamp\n",
    "  \n",
    "  #### - edited end ---- SB and SS 02292024\n",
    "  \n",
    "  # \n",
    "  # manual_staff_data <- read_csv(\"Wade_StaffGauge_2017-2022.csv\", col_types = cols())  %>% \n",
    "  #   mutate(r_timestamp =  mdy_hm(timestamp, tz = \"Etc/GMT+4\"))\n",
    "  \n",
    "  \n",
    "  \n",
    "  manual_staff_data <- df2 # edited by SB SS\n",
    "  \n",
    "  hobo_stage_data_filename <- df1 # edited by SB SS\n",
    "  \n",
    "  \n",
    "  # #setwd(\"/Users/erinseybold/ownCloud/BREE (2)/Watershed Data/Streams/02_site_data/discharge\") # for MAC\n",
    "  # \n",
    "  # # 2020 use wd from above-sb\n",
    "  # HF_stage_data_filename <- \"HB_Stage_2022_COMPILED.csv\" #raw stage data - change this to file for analysis\n",
    "  # \n",
    "  \n",
    "  # Load data ---------------------------------------------------------------\n",
    "  HF_sensor_data <- df1\n",
    "  \n",
    "  # Convert timestamps\n",
    "  # HF_sensor_data$r_timestamp <- as.POSIXct(strptime(HF_sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "  # HF_sensor_data$timestamp <- NULL\n",
    "  HF_sensor_data$r_timestamp <- HF_sensor_data$Timestamp\n",
    "  \n",
    "  \n",
    "  \n",
    "  HF_sensor_data$offset <- 0.1597 # this corrects the measured stage to the USGS stage so that the USGS rating curve can be used on NEWRnet stage time series\n",
    "  \n",
    "  #HF_sensor_data$corr_stage <- HF_sensor_data$hobo_stage-HF_sensor_data$offset # only need this for years 2014-20189\n",
    "  \n",
    "  #HF_sensor_data$corr_stage_2019 <- 0.793*HF_sensor_data$corr_stage + 0.2366 # specific to 2019 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"HfordStage_2019_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    "  ### 2020 stage data corrected in aquarius using staff gauge readings no offset or correction needed in script-sb\n",
    "  \n",
    "  HF_sensor_data$stage <- HF_sensor_data$'Stage.StagemHOBO@Hungerford Brook' - 0.1597\n",
    "  \n",
    "  HF_sensor_data$HF_best_q <- 9.736*(HF_sensor_data$stage^2.2984)\n",
    "  \n",
    "  ggplot(HF_sensor_data, aes(r_timestamp,HF_best_q))+\n",
    "    geom_point(aes(), alpha = 0.8,  size = 2, shape = 21, colour = \"black\")+\n",
    "    ylim(0,4)\n",
    "  \n",
    "  # Export q data\n",
    "  write.csv(HF_sensor_data, \"hungerford_2023_best_q.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff005ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
