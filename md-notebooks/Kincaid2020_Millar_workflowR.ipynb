{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ea645",
   "metadata": {},
   "source": [
    "## This notebook details practicing and playing around with Millar et al's R code for automatic event delineation and hysteresis calcs using the s::can and discharge data from [Kincaid et al., 2020](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR027361) \n",
    "\n",
    "- ### Data publicly available here on HydroShare: https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "\n",
    "- ### This larger dataset includes the 2014-2015 discharge and nitrate data from Vaughan, M. (2017). Vermont NEWRnet stations: 2014-2015 high-frequency DOC, nitrate, and discharge data, HydroShare, http://www.hydroshare.org/resource/faac1672244c407e9c9c8644c8211fd6.\n",
    "\n",
    "- ### I downloaded on 05.02.24 and put it here in this directory /home/millieginty/Documents/git-repos/cQ_analysis/millar2021_R_partition_hysteresis\n",
    "\n",
    "- ### The raw data file has discharge (q m3s), NO3, and SRP with timestamp and event start/end times for each watershed. The Millar code takes just timestamp, q, and C input csvs so I'll separate this raw data file into just those parameters for each site over the entire time period (>400 events from 2014 to 2018, no winter events)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca3a8707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# LOAD PACKAGES #\n",
    "#################\n",
    "\n",
    "library(tidyverse)\n",
    "library(viridis)\n",
    "\n",
    "###################\n",
    "# SET DIRECTORIES #\n",
    "###################\n",
    "\n",
    "# Define the input and output directories\n",
    "\n",
    "# For Kincaid data, input and output in separate directory\n",
    "input_dir <- \"/home/millieginty/Documents/git-repos/cQ_analysis/millar2021_R_partition_hysteresis/kincaid2020_hydroshare/\"\n",
    "output_dir <- \"/home/millieginty/Documents/git-repos/cQ_analysis/millar2021_R_partition_hysteresis/kincaid2020_hydroshare/output/\"\n",
    "\n",
    "# functions script in main millar directory\n",
    "millar_input_dir <- \"/home/millieginty/Documents/git-repos/cQ_analysis/millar2021_R_partition_hysteresis/\"\n",
    "\n",
    "#####################\n",
    "# READ IN FUNCTIONS #\n",
    "#####################\n",
    "\n",
    "# MED note: I haven't altered anything in this functions script\n",
    "source(file.path(millar_input_dir,\"cQ_functions.R\"))\n",
    "\n",
    "################\n",
    "# READ IN DATA #\n",
    "################\n",
    "\n",
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir,\"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Filter the data for just Hungerford Brook\n",
    "# Rename whatever constituent to 'conc'\n",
    "Hford <- allInputData15Min %>%\n",
    "  filter(site == \"Hungerford\") %>%\n",
    "  select(datetime = timestamp, q_cms, conc = NO3_mgNL)\n",
    "\n",
    "# Specify constituent in data set name\n",
    "dataSetName <- \"HF_NO3\"\n",
    "\n",
    "# Chose constitution for plot axes labels (NO3, TOC, or turbidity)\n",
    "constit <- \"NO3\"\n",
    "\n",
    "# MED note that I had to change the column in the Kincaid dataset to 'datetime' from 'timestamp' and also added seconds\n",
    "Hford$datetime <- as.POSIXct(Hford$datetime,format(\"%m/%d/%Y %H:%M:%S\"),tz=\"EST\")\n",
    "\n",
    "# Rescle the data\n",
    "Hford <- Hford %>% \n",
    "  mutate(rescaled_conc = ((conc-min(conc))/(max(conc)-min(conc))*max(q_cms)))\n",
    "\n",
    "# Vector containing candidate baseflow separation filter values\n",
    "candidateFilterPara <- c(0.99,0.98)\n",
    "\n",
    "# Vector containing candidate stormflow threshold values\n",
    "#candidateSfThresh <- c(0.01,0.003,0.05) # Millar et al 2021 values\n",
    "candidateSfThresh <- c(1.5,3.0,4.8) # MED HF guess values\n",
    "\n",
    "# Vector with interpolation intervals used for calculating HI\n",
    "interp <- seq(0,1,0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d01f243",
   "metadata": {},
   "source": [
    "### Now, running the Millar code to get hysteresis indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f326c90",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in if (flowData$storm_y_n[dt] == \"yes\" & flowData$storm_y_n[dt - : missing value where TRUE/FALSE needed\n",
     "output_type": "error",
     "traceback": [
      "Error in if (flowData$storm_y_n[dt] == \"yes\" & flowData$storm_y_n[dt - : missing value where TRUE/FALSE needed\nTraceback:\n",
      "1. batchRunBfAndEvSepForCQ(qInputs = Hford, bfSepPasses = 3, filterParam = candidateFilterPara, \n .     sfSmoothPasses = 4, sfThresh = candidateSfThresh, cInputs = Hford, \n .     timeStep = 15, minDuration = 2, maxDuration = 200)",
      "2. baseFlowEventSep(smoothStFlow = smoothStorm, sfThresh = sfThreshValue)"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# RUN ANALYSIS TO GET HYSTERESIS INDICES #\n",
    "##########################################\n",
    "\n",
    "batchRun1 <- batchRunBfAndEvSepForCQ(qInputs = Hford,\n",
    "                                     bfSepPasses = 3,\n",
    "                                     filterParam = candidateFilterPara,\n",
    "                                     sfSmoothPasses = 4,\n",
    "                                     sfThresh = candidateSfThresh,\n",
    "                                     cInputs = Hford,\n",
    "                                     timeStep = 15,\n",
    "                                     minDuration = 2,\n",
    "                                     maxDuration = 200)\n",
    "\n",
    "eventsDataAll1 <- getAllStormEvents(batchRun = batchRun1,\n",
    "                                    timestep_min = 15)\n",
    "\n",
    "batchRunFlowsLF1 <- batchRunflowCompare(qData = Hford,\n",
    "                                         bfSepPasses = 4,\n",
    "                                         filterPara = candidateFilterPara,\n",
    "                                         sfSmoothPasses = 4)\n",
    "\n",
    "eventsData1 <- stormEventCalcs(batchRun = batchRun1,\n",
    "                               timestep_min = 15)\n",
    "\n",
    "stormCounts1 <- stormCounts(batchRun1)\n",
    "\n",
    "hysteresisData1 <- getHysteresisIndices(batchRun = batchRun1,\n",
    "                                        xForInterp = interp,\n",
    "                                        eventsData = eventsData1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c29052",
   "metadata": {},
   "source": [
    "### Export the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70789c57",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(x): object 'eventsData1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(x): object 'eventsData1' not found\nTraceback:\n",
      "1. write.csv(eventsData1, file = file.path(output_dir, paste(dataSetName, \n .     \"_StormEventSummaryData.csv\", sep = \"\")))",
      "2. eval.parent(Call)",
      "3. eval(expr, p)",
      "4. eval(expr, p)",
      "5. utils::write.table(eventsData1, file = file.path(output_dir, \n .     paste(dataSetName, \"_StormEventSummaryData.csv\", sep = \"\")), \n .     col.names = NA, sep = \",\", dec = \".\", qmethod = \"double\")",
      "6. is.data.frame(x)"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# EXPORT OUTPUT DATA #\n",
    "######################\n",
    "\n",
    "write.csv(eventsData1,file = file.path(output_dir,paste(dataSetName,\"_StormEventSummaryData.csv\",sep=\"\")))\n",
    "write.csv(batchRunFlowsLF1,file = file.path(output_dir,paste(dataSetName,\"_DischargeData.csv\",sep=\"\")))\n",
    "write.csv(hysteresisData1,file = file.path(output_dir,paste(dataSetName,\"_HysteresisData.csv\",sep=\"\")))\n",
    "write.csv(eventsDataAll1,file = file.path(output_dir,paste(dataSetName,\"_AllCQData.csv\",sep=\"\")))\n",
    "write.csv(stormCounts1,file = file.path(output_dir,paste(dataSetName,\"_StormCounts.csv\",sep=\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ddd30a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
