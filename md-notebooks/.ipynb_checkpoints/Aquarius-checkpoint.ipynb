{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada7e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/millieginty/R/x86_64-pc-linux-gnu-library/4.1’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependencies ‘gridGraphics’, ‘yulab.utils’, ‘plyr’, ‘lmodel2’, ‘reshape2’, ‘ggplotify’, ‘ggnewscale’, ‘patchwork’\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages('foqat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbc38fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 34924 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Timestamp</th><th scope=col>Sp Cond.SpecCond@Wade Brook</th><th scope=col>timestamp</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dttm&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dttm&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>2022-01-01 00:02:00</td><td>30.28</td><td>2022-01-01 00:02:00</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2022-01-01 00:17:00</td><td>30.28</td><td>2022-01-01 00:17:00</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>2022-01-01 00:32:00</td><td>30.28</td><td>2022-01-01 00:32:00</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>2022-01-01 00:47:00</td><td>30.23</td><td>2022-01-01 00:47:00</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2022-01-01 01:02:00</td><td>30.21</td><td>2022-01-01 01:02:00</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>2022-01-01 01:17:00</td><td>30.21</td><td>2022-01-01 01:17:00</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>2022-01-01 01:32:00</td><td>30.18</td><td>2022-01-01 01:32:00</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>2022-01-01 01:47:00</td><td>30.17</td><td>2022-01-01 01:47:00</td></tr>\n",
       "\t<tr><th scope=row>9</th><td>2022-01-01 02:02:00</td><td>30.14</td><td>2022-01-01 02:02:00</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>2022-01-01 02:17:00</td><td>30.15</td><td>2022-01-01 02:17:00</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>2022-01-01 02:32:00</td><td>30.14</td><td>2022-01-01 02:32:00</td></tr>\n",
       "\t<tr><th scope=row>12</th><td>2022-01-01 02:47:00</td><td>30.16</td><td>2022-01-01 02:47:00</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>2022-01-01 03:02:00</td><td>30.16</td><td>2022-01-01 03:02:00</td></tr>\n",
       "\t<tr><th scope=row>14</th><td>2022-01-01 03:17:00</td><td>30.16</td><td>2022-01-01 03:17:00</td></tr>\n",
       "\t<tr><th scope=row>15</th><td>2022-01-01 03:32:00</td><td>30.15</td><td>2022-01-01 03:32:00</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>2022-01-01 03:47:00</td><td>30.15</td><td>2022-01-01 03:47:00</td></tr>\n",
       "\t<tr><th scope=row>17</th><td>2022-01-01 04:02:00</td><td>30.18</td><td>2022-01-01 04:02:00</td></tr>\n",
       "\t<tr><th scope=row>18</th><td>2022-01-01 04:17:00</td><td>30.16</td><td>2022-01-01 04:17:00</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>2022-01-01 04:32:00</td><td>30.18</td><td>2022-01-01 04:32:00</td></tr>\n",
       "\t<tr><th scope=row>20</th><td>2022-01-01 04:47:00</td><td>30.17</td><td>2022-01-01 04:47:00</td></tr>\n",
       "\t<tr><th scope=row>21</th><td>2022-01-01 05:02:00</td><td>30.17</td><td>2022-01-01 05:02:00</td></tr>\n",
       "\t<tr><th scope=row>22</th><td>2022-01-01 05:17:00</td><td>30.17</td><td>2022-01-01 05:17:00</td></tr>\n",
       "\t<tr><th scope=row>23</th><td>2022-01-01 05:32:00</td><td>30.16</td><td>2022-01-01 05:32:00</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>2022-01-01 05:47:00</td><td>30.15</td><td>2022-01-01 05:47:00</td></tr>\n",
       "\t<tr><th scope=row>25</th><td>2022-01-01 06:02:00</td><td>30.15</td><td>2022-01-01 06:02:00</td></tr>\n",
       "\t<tr><th scope=row>26</th><td>2022-01-01 06:17:00</td><td>30.15</td><td>2022-01-01 06:17:00</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>2022-01-01 06:32:00</td><td>30.17</td><td>2022-01-01 06:32:00</td></tr>\n",
       "\t<tr><th scope=row>28</th><td>2022-01-01 06:47:00</td><td>30.14</td><td>2022-01-01 06:47:00</td></tr>\n",
       "\t<tr><th scope=row>29</th><td>2022-01-01 07:02:00</td><td>30.15</td><td>2022-01-01 07:02:00</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>2022-01-01 07:17:00</td><td>30.15</td><td>2022-01-01 07:17:00</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>34895</th><td>2022-12-30 16:32:00</td><td>21.13</td><td>2022-12-30 16:32:00</td></tr>\n",
       "\t<tr><th scope=row>34896</th><td>2022-12-30 16:47:00</td><td>21.04</td><td>2022-12-30 16:47:00</td></tr>\n",
       "\t<tr><th scope=row>34897</th><td>2022-12-30 17:02:00</td><td>20.89</td><td>2022-12-30 17:02:00</td></tr>\n",
       "\t<tr><th scope=row>34898</th><td>2022-12-30 17:17:00</td><td>20.82</td><td>2022-12-30 17:17:00</td></tr>\n",
       "\t<tr><th scope=row>34899</th><td>2022-12-30 17:32:00</td><td>20.70</td><td>2022-12-30 17:32:00</td></tr>\n",
       "\t<tr><th scope=row>34900</th><td>2022-12-30 17:47:00</td><td>20.62</td><td>2022-12-30 17:47:00</td></tr>\n",
       "\t<tr><th scope=row>34901</th><td>2022-12-30 18:02:00</td><td>20.57</td><td>2022-12-30 18:02:00</td></tr>\n",
       "\t<tr><th scope=row>34902</th><td>2022-12-30 18:17:00</td><td>20.39</td><td>2022-12-30 18:17:00</td></tr>\n",
       "\t<tr><th scope=row>34903</th><td>2022-12-30 18:32:00</td><td>20.34</td><td>2022-12-30 18:32:00</td></tr>\n",
       "\t<tr><th scope=row>34904</th><td>2022-12-30 18:47:00</td><td>20.27</td><td>2022-12-30 18:47:00</td></tr>\n",
       "\t<tr><th scope=row>34905</th><td>2022-12-30 19:02:00</td><td>20.17</td><td>2022-12-30 19:02:00</td></tr>\n",
       "\t<tr><th scope=row>34906</th><td>2022-12-30 19:17:00</td><td>20.15</td><td>2022-12-30 19:17:00</td></tr>\n",
       "\t<tr><th scope=row>34907</th><td>2022-12-30 19:32:00</td><td>20.13</td><td>2022-12-30 19:32:00</td></tr>\n",
       "\t<tr><th scope=row>34908</th><td>2022-12-30 19:47:00</td><td>20.05</td><td>2022-12-30 19:47:00</td></tr>\n",
       "\t<tr><th scope=row>34909</th><td>2022-12-30 20:02:00</td><td>20.03</td><td>2022-12-30 20:02:00</td></tr>\n",
       "\t<tr><th scope=row>34910</th><td>2022-12-30 20:17:10</td><td>19.95</td><td>2022-12-30 20:17:10</td></tr>\n",
       "\t<tr><th scope=row>34911</th><td>2022-12-30 20:32:10</td><td>19.99</td><td>2022-12-30 20:32:10</td></tr>\n",
       "\t<tr><th scope=row>34912</th><td>2022-12-30 20:47:10</td><td>19.88</td><td>2022-12-30 20:47:10</td></tr>\n",
       "\t<tr><th scope=row>34913</th><td>2022-12-30 21:02:00</td><td>19.84</td><td>2022-12-30 21:02:00</td></tr>\n",
       "\t<tr><th scope=row>34914</th><td>2022-12-30 21:17:00</td><td>19.81</td><td>2022-12-30 21:17:00</td></tr>\n",
       "\t<tr><th scope=row>34915</th><td>2022-12-30 21:32:00</td><td>19.77</td><td>2022-12-30 21:32:00</td></tr>\n",
       "\t<tr><th scope=row>34916</th><td>2022-12-30 21:47:00</td><td>19.73</td><td>2022-12-30 21:47:00</td></tr>\n",
       "\t<tr><th scope=row>34917</th><td>2022-12-30 22:02:00</td><td>19.75</td><td>2022-12-30 22:02:00</td></tr>\n",
       "\t<tr><th scope=row>34918</th><td>2022-12-30 22:17:00</td><td>19.64</td><td>2022-12-30 22:17:00</td></tr>\n",
       "\t<tr><th scope=row>34919</th><td>2022-12-30 22:32:00</td><td>19.61</td><td>2022-12-30 22:32:00</td></tr>\n",
       "\t<tr><th scope=row>34920</th><td>2022-12-30 22:47:00</td><td>19.56</td><td>2022-12-30 22:47:00</td></tr>\n",
       "\t<tr><th scope=row>34921</th><td>2022-12-30 23:02:00</td><td>19.51</td><td>2022-12-30 23:02:00</td></tr>\n",
       "\t<tr><th scope=row>34922</th><td>2022-12-30 23:17:00</td><td>19.51</td><td>2022-12-30 23:17:00</td></tr>\n",
       "\t<tr><th scope=row>34923</th><td>2022-12-30 23:32:00</td><td>19.44</td><td>2022-12-30 23:32:00</td></tr>\n",
       "\t<tr><th scope=row>34924</th><td>2022-12-30 23:47:00</td><td>19.36</td><td>2022-12-30 23:47:00</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 34924 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Timestamp & Sp Cond.SpecCond@Wade Brook & timestamp\\\\\n",
       "  & <dttm> & <dbl> & <dttm>\\\\\n",
       "\\hline\n",
       "\t1 & 2022-01-01 00:02:00 & 30.28 & 2022-01-01 00:02:00\\\\\n",
       "\t2 & 2022-01-01 00:17:00 & 30.28 & 2022-01-01 00:17:00\\\\\n",
       "\t3 & 2022-01-01 00:32:00 & 30.28 & 2022-01-01 00:32:00\\\\\n",
       "\t4 & 2022-01-01 00:47:00 & 30.23 & 2022-01-01 00:47:00\\\\\n",
       "\t5 & 2022-01-01 01:02:00 & 30.21 & 2022-01-01 01:02:00\\\\\n",
       "\t6 & 2022-01-01 01:17:00 & 30.21 & 2022-01-01 01:17:00\\\\\n",
       "\t7 & 2022-01-01 01:32:00 & 30.18 & 2022-01-01 01:32:00\\\\\n",
       "\t8 & 2022-01-01 01:47:00 & 30.17 & 2022-01-01 01:47:00\\\\\n",
       "\t9 & 2022-01-01 02:02:00 & 30.14 & 2022-01-01 02:02:00\\\\\n",
       "\t10 & 2022-01-01 02:17:00 & 30.15 & 2022-01-01 02:17:00\\\\\n",
       "\t11 & 2022-01-01 02:32:00 & 30.14 & 2022-01-01 02:32:00\\\\\n",
       "\t12 & 2022-01-01 02:47:00 & 30.16 & 2022-01-01 02:47:00\\\\\n",
       "\t13 & 2022-01-01 03:02:00 & 30.16 & 2022-01-01 03:02:00\\\\\n",
       "\t14 & 2022-01-01 03:17:00 & 30.16 & 2022-01-01 03:17:00\\\\\n",
       "\t15 & 2022-01-01 03:32:00 & 30.15 & 2022-01-01 03:32:00\\\\\n",
       "\t16 & 2022-01-01 03:47:00 & 30.15 & 2022-01-01 03:47:00\\\\\n",
       "\t17 & 2022-01-01 04:02:00 & 30.18 & 2022-01-01 04:02:00\\\\\n",
       "\t18 & 2022-01-01 04:17:00 & 30.16 & 2022-01-01 04:17:00\\\\\n",
       "\t19 & 2022-01-01 04:32:00 & 30.18 & 2022-01-01 04:32:00\\\\\n",
       "\t20 & 2022-01-01 04:47:00 & 30.17 & 2022-01-01 04:47:00\\\\\n",
       "\t21 & 2022-01-01 05:02:00 & 30.17 & 2022-01-01 05:02:00\\\\\n",
       "\t22 & 2022-01-01 05:17:00 & 30.17 & 2022-01-01 05:17:00\\\\\n",
       "\t23 & 2022-01-01 05:32:00 & 30.16 & 2022-01-01 05:32:00\\\\\n",
       "\t24 & 2022-01-01 05:47:00 & 30.15 & 2022-01-01 05:47:00\\\\\n",
       "\t25 & 2022-01-01 06:02:00 & 30.15 & 2022-01-01 06:02:00\\\\\n",
       "\t26 & 2022-01-01 06:17:00 & 30.15 & 2022-01-01 06:17:00\\\\\n",
       "\t27 & 2022-01-01 06:32:00 & 30.17 & 2022-01-01 06:32:00\\\\\n",
       "\t28 & 2022-01-01 06:47:00 & 30.14 & 2022-01-01 06:47:00\\\\\n",
       "\t29 & 2022-01-01 07:02:00 & 30.15 & 2022-01-01 07:02:00\\\\\n",
       "\t30 & 2022-01-01 07:17:00 & 30.15 & 2022-01-01 07:17:00\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t34895 & 2022-12-30 16:32:00 & 21.13 & 2022-12-30 16:32:00\\\\\n",
       "\t34896 & 2022-12-30 16:47:00 & 21.04 & 2022-12-30 16:47:00\\\\\n",
       "\t34897 & 2022-12-30 17:02:00 & 20.89 & 2022-12-30 17:02:00\\\\\n",
       "\t34898 & 2022-12-30 17:17:00 & 20.82 & 2022-12-30 17:17:00\\\\\n",
       "\t34899 & 2022-12-30 17:32:00 & 20.70 & 2022-12-30 17:32:00\\\\\n",
       "\t34900 & 2022-12-30 17:47:00 & 20.62 & 2022-12-30 17:47:00\\\\\n",
       "\t34901 & 2022-12-30 18:02:00 & 20.57 & 2022-12-30 18:02:00\\\\\n",
       "\t34902 & 2022-12-30 18:17:00 & 20.39 & 2022-12-30 18:17:00\\\\\n",
       "\t34903 & 2022-12-30 18:32:00 & 20.34 & 2022-12-30 18:32:00\\\\\n",
       "\t34904 & 2022-12-30 18:47:00 & 20.27 & 2022-12-30 18:47:00\\\\\n",
       "\t34905 & 2022-12-30 19:02:00 & 20.17 & 2022-12-30 19:02:00\\\\\n",
       "\t34906 & 2022-12-30 19:17:00 & 20.15 & 2022-12-30 19:17:00\\\\\n",
       "\t34907 & 2022-12-30 19:32:00 & 20.13 & 2022-12-30 19:32:00\\\\\n",
       "\t34908 & 2022-12-30 19:47:00 & 20.05 & 2022-12-30 19:47:00\\\\\n",
       "\t34909 & 2022-12-30 20:02:00 & 20.03 & 2022-12-30 20:02:00\\\\\n",
       "\t34910 & 2022-12-30 20:17:10 & 19.95 & 2022-12-30 20:17:10\\\\\n",
       "\t34911 & 2022-12-30 20:32:10 & 19.99 & 2022-12-30 20:32:10\\\\\n",
       "\t34912 & 2022-12-30 20:47:10 & 19.88 & 2022-12-30 20:47:10\\\\\n",
       "\t34913 & 2022-12-30 21:02:00 & 19.84 & 2022-12-30 21:02:00\\\\\n",
       "\t34914 & 2022-12-30 21:17:00 & 19.81 & 2022-12-30 21:17:00\\\\\n",
       "\t34915 & 2022-12-30 21:32:00 & 19.77 & 2022-12-30 21:32:00\\\\\n",
       "\t34916 & 2022-12-30 21:47:00 & 19.73 & 2022-12-30 21:47:00\\\\\n",
       "\t34917 & 2022-12-30 22:02:00 & 19.75 & 2022-12-30 22:02:00\\\\\n",
       "\t34918 & 2022-12-30 22:17:00 & 19.64 & 2022-12-30 22:17:00\\\\\n",
       "\t34919 & 2022-12-30 22:32:00 & 19.61 & 2022-12-30 22:32:00\\\\\n",
       "\t34920 & 2022-12-30 22:47:00 & 19.56 & 2022-12-30 22:47:00\\\\\n",
       "\t34921 & 2022-12-30 23:02:00 & 19.51 & 2022-12-30 23:02:00\\\\\n",
       "\t34922 & 2022-12-30 23:17:00 & 19.51 & 2022-12-30 23:17:00\\\\\n",
       "\t34923 & 2022-12-30 23:32:00 & 19.44 & 2022-12-30 23:32:00\\\\\n",
       "\t34924 & 2022-12-30 23:47:00 & 19.36 & 2022-12-30 23:47:00\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 34924 × 3\n",
       "\n",
       "| <!--/--> | Timestamp &lt;dttm&gt; | Sp Cond.SpecCond@Wade Brook &lt;dbl&gt; | timestamp &lt;dttm&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 2022-01-01 00:02:00 | 30.28 | 2022-01-01 00:02:00 |\n",
       "| 2 | 2022-01-01 00:17:00 | 30.28 | 2022-01-01 00:17:00 |\n",
       "| 3 | 2022-01-01 00:32:00 | 30.28 | 2022-01-01 00:32:00 |\n",
       "| 4 | 2022-01-01 00:47:00 | 30.23 | 2022-01-01 00:47:00 |\n",
       "| 5 | 2022-01-01 01:02:00 | 30.21 | 2022-01-01 01:02:00 |\n",
       "| 6 | 2022-01-01 01:17:00 | 30.21 | 2022-01-01 01:17:00 |\n",
       "| 7 | 2022-01-01 01:32:00 | 30.18 | 2022-01-01 01:32:00 |\n",
       "| 8 | 2022-01-01 01:47:00 | 30.17 | 2022-01-01 01:47:00 |\n",
       "| 9 | 2022-01-01 02:02:00 | 30.14 | 2022-01-01 02:02:00 |\n",
       "| 10 | 2022-01-01 02:17:00 | 30.15 | 2022-01-01 02:17:00 |\n",
       "| 11 | 2022-01-01 02:32:00 | 30.14 | 2022-01-01 02:32:00 |\n",
       "| 12 | 2022-01-01 02:47:00 | 30.16 | 2022-01-01 02:47:00 |\n",
       "| 13 | 2022-01-01 03:02:00 | 30.16 | 2022-01-01 03:02:00 |\n",
       "| 14 | 2022-01-01 03:17:00 | 30.16 | 2022-01-01 03:17:00 |\n",
       "| 15 | 2022-01-01 03:32:00 | 30.15 | 2022-01-01 03:32:00 |\n",
       "| 16 | 2022-01-01 03:47:00 | 30.15 | 2022-01-01 03:47:00 |\n",
       "| 17 | 2022-01-01 04:02:00 | 30.18 | 2022-01-01 04:02:00 |\n",
       "| 18 | 2022-01-01 04:17:00 | 30.16 | 2022-01-01 04:17:00 |\n",
       "| 19 | 2022-01-01 04:32:00 | 30.18 | 2022-01-01 04:32:00 |\n",
       "| 20 | 2022-01-01 04:47:00 | 30.17 | 2022-01-01 04:47:00 |\n",
       "| 21 | 2022-01-01 05:02:00 | 30.17 | 2022-01-01 05:02:00 |\n",
       "| 22 | 2022-01-01 05:17:00 | 30.17 | 2022-01-01 05:17:00 |\n",
       "| 23 | 2022-01-01 05:32:00 | 30.16 | 2022-01-01 05:32:00 |\n",
       "| 24 | 2022-01-01 05:47:00 | 30.15 | 2022-01-01 05:47:00 |\n",
       "| 25 | 2022-01-01 06:02:00 | 30.15 | 2022-01-01 06:02:00 |\n",
       "| 26 | 2022-01-01 06:17:00 | 30.15 | 2022-01-01 06:17:00 |\n",
       "| 27 | 2022-01-01 06:32:00 | 30.17 | 2022-01-01 06:32:00 |\n",
       "| 28 | 2022-01-01 06:47:00 | 30.14 | 2022-01-01 06:47:00 |\n",
       "| 29 | 2022-01-01 07:02:00 | 30.15 | 2022-01-01 07:02:00 |\n",
       "| 30 | 2022-01-01 07:17:00 | 30.15 | 2022-01-01 07:17:00 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 34895 | 2022-12-30 16:32:00 | 21.13 | 2022-12-30 16:32:00 |\n",
       "| 34896 | 2022-12-30 16:47:00 | 21.04 | 2022-12-30 16:47:00 |\n",
       "| 34897 | 2022-12-30 17:02:00 | 20.89 | 2022-12-30 17:02:00 |\n",
       "| 34898 | 2022-12-30 17:17:00 | 20.82 | 2022-12-30 17:17:00 |\n",
       "| 34899 | 2022-12-30 17:32:00 | 20.70 | 2022-12-30 17:32:00 |\n",
       "| 34900 | 2022-12-30 17:47:00 | 20.62 | 2022-12-30 17:47:00 |\n",
       "| 34901 | 2022-12-30 18:02:00 | 20.57 | 2022-12-30 18:02:00 |\n",
       "| 34902 | 2022-12-30 18:17:00 | 20.39 | 2022-12-30 18:17:00 |\n",
       "| 34903 | 2022-12-30 18:32:00 | 20.34 | 2022-12-30 18:32:00 |\n",
       "| 34904 | 2022-12-30 18:47:00 | 20.27 | 2022-12-30 18:47:00 |\n",
       "| 34905 | 2022-12-30 19:02:00 | 20.17 | 2022-12-30 19:02:00 |\n",
       "| 34906 | 2022-12-30 19:17:00 | 20.15 | 2022-12-30 19:17:00 |\n",
       "| 34907 | 2022-12-30 19:32:00 | 20.13 | 2022-12-30 19:32:00 |\n",
       "| 34908 | 2022-12-30 19:47:00 | 20.05 | 2022-12-30 19:47:00 |\n",
       "| 34909 | 2022-12-30 20:02:00 | 20.03 | 2022-12-30 20:02:00 |\n",
       "| 34910 | 2022-12-30 20:17:10 | 19.95 | 2022-12-30 20:17:10 |\n",
       "| 34911 | 2022-12-30 20:32:10 | 19.99 | 2022-12-30 20:32:10 |\n",
       "| 34912 | 2022-12-30 20:47:10 | 19.88 | 2022-12-30 20:47:10 |\n",
       "| 34913 | 2022-12-30 21:02:00 | 19.84 | 2022-12-30 21:02:00 |\n",
       "| 34914 | 2022-12-30 21:17:00 | 19.81 | 2022-12-30 21:17:00 |\n",
       "| 34915 | 2022-12-30 21:32:00 | 19.77 | 2022-12-30 21:32:00 |\n",
       "| 34916 | 2022-12-30 21:47:00 | 19.73 | 2022-12-30 21:47:00 |\n",
       "| 34917 | 2022-12-30 22:02:00 | 19.75 | 2022-12-30 22:02:00 |\n",
       "| 34918 | 2022-12-30 22:17:00 | 19.64 | 2022-12-30 22:17:00 |\n",
       "| 34919 | 2022-12-30 22:32:00 | 19.61 | 2022-12-30 22:32:00 |\n",
       "| 34920 | 2022-12-30 22:47:00 | 19.56 | 2022-12-30 22:47:00 |\n",
       "| 34921 | 2022-12-30 23:02:00 | 19.51 | 2022-12-30 23:02:00 |\n",
       "| 34922 | 2022-12-30 23:17:00 | 19.51 | 2022-12-30 23:17:00 |\n",
       "| 34923 | 2022-12-30 23:32:00 | 19.44 | 2022-12-30 23:32:00 |\n",
       "| 34924 | 2022-12-30 23:47:00 | 19.36 | 2022-12-30 23:47:00 |\n",
       "\n"
      ],
      "text/plain": [
       "      Timestamp           Sp Cond.SpecCond@Wade Brook timestamp          \n",
       "1     2022-01-01 00:02:00 30.28                       2022-01-01 00:02:00\n",
       "2     2022-01-01 00:17:00 30.28                       2022-01-01 00:17:00\n",
       "3     2022-01-01 00:32:00 30.28                       2022-01-01 00:32:00\n",
       "4     2022-01-01 00:47:00 30.23                       2022-01-01 00:47:00\n",
       "5     2022-01-01 01:02:00 30.21                       2022-01-01 01:02:00\n",
       "6     2022-01-01 01:17:00 30.21                       2022-01-01 01:17:00\n",
       "7     2022-01-01 01:32:00 30.18                       2022-01-01 01:32:00\n",
       "8     2022-01-01 01:47:00 30.17                       2022-01-01 01:47:00\n",
       "9     2022-01-01 02:02:00 30.14                       2022-01-01 02:02:00\n",
       "10    2022-01-01 02:17:00 30.15                       2022-01-01 02:17:00\n",
       "11    2022-01-01 02:32:00 30.14                       2022-01-01 02:32:00\n",
       "12    2022-01-01 02:47:00 30.16                       2022-01-01 02:47:00\n",
       "13    2022-01-01 03:02:00 30.16                       2022-01-01 03:02:00\n",
       "14    2022-01-01 03:17:00 30.16                       2022-01-01 03:17:00\n",
       "15    2022-01-01 03:32:00 30.15                       2022-01-01 03:32:00\n",
       "16    2022-01-01 03:47:00 30.15                       2022-01-01 03:47:00\n",
       "17    2022-01-01 04:02:00 30.18                       2022-01-01 04:02:00\n",
       "18    2022-01-01 04:17:00 30.16                       2022-01-01 04:17:00\n",
       "19    2022-01-01 04:32:00 30.18                       2022-01-01 04:32:00\n",
       "20    2022-01-01 04:47:00 30.17                       2022-01-01 04:47:00\n",
       "21    2022-01-01 05:02:00 30.17                       2022-01-01 05:02:00\n",
       "22    2022-01-01 05:17:00 30.17                       2022-01-01 05:17:00\n",
       "23    2022-01-01 05:32:00 30.16                       2022-01-01 05:32:00\n",
       "24    2022-01-01 05:47:00 30.15                       2022-01-01 05:47:00\n",
       "25    2022-01-01 06:02:00 30.15                       2022-01-01 06:02:00\n",
       "26    2022-01-01 06:17:00 30.15                       2022-01-01 06:17:00\n",
       "27    2022-01-01 06:32:00 30.17                       2022-01-01 06:32:00\n",
       "28    2022-01-01 06:47:00 30.14                       2022-01-01 06:47:00\n",
       "29    2022-01-01 07:02:00 30.15                       2022-01-01 07:02:00\n",
       "30    2022-01-01 07:17:00 30.15                       2022-01-01 07:17:00\n",
       "⋮     ⋮                   ⋮                           ⋮                  \n",
       "34895 2022-12-30 16:32:00 21.13                       2022-12-30 16:32:00\n",
       "34896 2022-12-30 16:47:00 21.04                       2022-12-30 16:47:00\n",
       "34897 2022-12-30 17:02:00 20.89                       2022-12-30 17:02:00\n",
       "34898 2022-12-30 17:17:00 20.82                       2022-12-30 17:17:00\n",
       "34899 2022-12-30 17:32:00 20.70                       2022-12-30 17:32:00\n",
       "34900 2022-12-30 17:47:00 20.62                       2022-12-30 17:47:00\n",
       "34901 2022-12-30 18:02:00 20.57                       2022-12-30 18:02:00\n",
       "34902 2022-12-30 18:17:00 20.39                       2022-12-30 18:17:00\n",
       "34903 2022-12-30 18:32:00 20.34                       2022-12-30 18:32:00\n",
       "34904 2022-12-30 18:47:00 20.27                       2022-12-30 18:47:00\n",
       "34905 2022-12-30 19:02:00 20.17                       2022-12-30 19:02:00\n",
       "34906 2022-12-30 19:17:00 20.15                       2022-12-30 19:17:00\n",
       "34907 2022-12-30 19:32:00 20.13                       2022-12-30 19:32:00\n",
       "34908 2022-12-30 19:47:00 20.05                       2022-12-30 19:47:00\n",
       "34909 2022-12-30 20:02:00 20.03                       2022-12-30 20:02:00\n",
       "34910 2022-12-30 20:17:10 19.95                       2022-12-30 20:17:10\n",
       "34911 2022-12-30 20:32:10 19.99                       2022-12-30 20:32:10\n",
       "34912 2022-12-30 20:47:10 19.88                       2022-12-30 20:47:10\n",
       "34913 2022-12-30 21:02:00 19.84                       2022-12-30 21:02:00\n",
       "34914 2022-12-30 21:17:00 19.81                       2022-12-30 21:17:00\n",
       "34915 2022-12-30 21:32:00 19.77                       2022-12-30 21:32:00\n",
       "34916 2022-12-30 21:47:00 19.73                       2022-12-30 21:47:00\n",
       "34917 2022-12-30 22:02:00 19.75                       2022-12-30 22:02:00\n",
       "34918 2022-12-30 22:17:00 19.64                       2022-12-30 22:17:00\n",
       "34919 2022-12-30 22:32:00 19.61                       2022-12-30 22:32:00\n",
       "34920 2022-12-30 22:47:00 19.56                       2022-12-30 22:47:00\n",
       "34921 2022-12-30 23:02:00 19.51                       2022-12-30 23:02:00\n",
       "34922 2022-12-30 23:17:00 19.51                       2022-12-30 23:17:00\n",
       "34923 2022-12-30 23:32:00 19.44                       2022-12-30 23:32:00\n",
       "34924 2022-12-30 23:47:00 19.36                       2022-12-30 23:47:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Written by Matthew CH Vaughan\n",
    "# edited/adapted by Erin Seybold on 3/16/18\n",
    "# edited by SB, SS on 02292024\n",
    "# editied by Megan Duffy on 05/28/24\n",
    "\n",
    "library(ggplot2)\n",
    "library(\"tidyverse\")\n",
    "library(\"lubridate\")\n",
    "library(\"foqat\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------  \n",
    "# -------------------------------------------------------------------------  \n",
    "# ------------------------------------- WADE ------------------------------  \n",
    "# User inputs -------------------------------------------------------------\n",
    "\n",
    "#setwd(\"/Users/mat/OneDrive - University of Vermont/Watershed Data/Streams/02_site_data/discharge\") # for MAC\n",
    "# setwd(\"/Users/dustinkincaid/OneDrive - University of Vermont/Watershed Data/Streams/02_site_data/discharge\")\n",
    "# Import data\n",
    "\n",
    "# Import data\n",
    "setwd(\"/home/millieginty/Documents/git-repos/cQ_analysis/cond-hydrograph-separation/newrnet/data/\")\n",
    "\n",
    "#### - edited by SB and SS 02292024\n",
    "\n",
    "source(\"AquariusR/aquariusHelperFunctions.R\", chdir = T)\n",
    "\n",
    "aquariusLoginWithFile(\"AquariusR/aquariusLogin\")\n",
    "\n",
    "\n",
    "df1 <- getCorrectedAquariusDataSeries(\n",
    "  \"Sp Cond.SpecCond@Wade Brook\",\n",
    "  startTime = \"2022-01-01T00:00:00-05:00\",\n",
    "  endTime   = \"2022-12-31T00:00:00-05:00\")\n",
    "\n",
    "df1$timestamp <-df1$Timestamp\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5746ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: jsonlite\n",
      "\n",
      "\n",
      "Attaching package: ‘jsonlite’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    flatten\n",
      "\n",
      "\n",
      "Loading required package: httr\n",
      "\n",
      "Warning message in file(file, \"rt\"):\n",
      "“cannot open file 'scripts/20160908_wade_stage_q_data.csv': No such file or directory”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in file(file, \"rt\"): cannot open the connection\n",
     "output_type": "error",
     "traceback": [
      "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
      "1. read.csv(stage_discharge_filename)",
      "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
      "3. file(file, \"rt\")"
     ]
    }
   ],
   "source": [
    "df2 <- getCorrectedAquariusDataSeries(\n",
    "  \"Depth.Staff Ruler Height@Wade Brook\",\n",
    "  startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "  endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "\n",
    "df2$timestamp <-df2$Timestamp\n",
    "\n",
    "#### - edited end ---- SB and SS 02292024\n",
    "\n",
    "# \n",
    "# manual_staff_data <- read_csv(\"Wade_StaffGauge_2017-2022.csv\", col_types = cols())  %>% \n",
    "#   mutate(r_timestamp =  mdy_hm(timestamp, tz = \"Etc/GMT+4\"))\n",
    "\n",
    "\n",
    "\n",
    "manual_staff_data <- df2 # edited by SB SS\n",
    "\n",
    "\n",
    "stage_discharge_filename <- \"scripts/20160908_wade_stage_q_data.csv\" #rating curve info \n",
    "# hobo_stage_data_filename <- \"Wade_Stage_2022_COMPILED.csv\" #raw stage data - change this to file for analysis\n",
    "#staff_gauge_manual_readings <- \"Staff_gauge_readings/Wade_StaffGauge_2017-2020.csv\"\n",
    "\n",
    "hobo_stage_data_filename <- df1 # edited by SB SS\n",
    "\n",
    "dist_from_hobo_to_streambed <- 0.221716 # In meters. See excel spreadsheet for data+details on this calculation\n",
    "\n",
    "# Load data ---------------------------------------------------------------\n",
    "  # curve_data <- read.csv(stage_discharge_filename) - commented by SB SS Feb 2024\n",
    "  # sensor_data <- read.csv(hobo_stage_data_filename) - commented by SB SS Feb 2024\n",
    "#  manual_staff_data <- read.csv(staff_gauge_manual_readings)\n",
    "  \n",
    "# edited by SB SS 02292024\n",
    "  curve_data <- read.csv(stage_discharge_filename)\n",
    "  sensor_data <-df1 \n",
    "# end edit by SB SS 02292024\n",
    "\n",
    " # Adjust hobo stage to reflect distance above the streambed\n",
    "  curve_data$stage <- curve_data$hobo_stage + dist_from_hobo_to_streambed\n",
    "  \n",
    "  # for 2014-2017 - sensor_data doesn't needisd any additional processing other than the distance offset, for 2018 and 2019 see below.\n",
    "  \n",
    "  # for 2018\n",
    "  #sensor_data$hobo_stage_int <- 1.1225*sensor_data$hobo_stage + 0.164 # specific to 2018 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"WadeStage_2018_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    "  \n",
    "  # for 2019\n",
    "  #sensor_data$hobo_stage_int <- 0.9967*sensor_data$hobo_stage + 0.063 # specific to 2019 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"WadeStage_2019_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    " \n",
    "  # for 2020 data stage was corrected in aquarius using staff gauge readings\n",
    "  # sensor_data$Stage <- sensor_data$stage + dist_from_hobo_to_streambed\n",
    "  \n",
    "  # for 2020 \n",
    "  #sensor_data$hobo_stage_int <- 0.9163*sensor_data$hobo_stage + 0.1026 # specific to 2020 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"Wade_stage_manual_offset_2020\" for details on this correction (located in rating curve folder)\n",
    "\n",
    "  # for 2021 REVISED\n",
    "  #sensor_data$hobo_stage_int <- 0.876*sensor_data$hobo_stage + 0.1077 # specific to 2021 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"Wade_stage_manual_offset_2021\" for details on this correction (located in rating curve folder)\n",
    "\n",
    "  # for 2022 REVISED\n",
    "  #corrections already applied to \"Wade_Stage_2022_COMPILED.csv\" file, see file \"Wade_stage_manual_offset_2021\" for details on this correction (located in rating curve folder)\n",
    "    \n",
    "  # sensor_data$stage <- sensor_data$hobo_stage + dist_from_hobo_to_streambed # for 2014-2018 years, this is the final stage and can be renamed/line below can be commented out\n",
    "  \n",
    "  sensor_data$stage <- sensor_data$'Stage.Stage@Wade Brook' + dist_from_hobo_to_streambed # for 2014-2018 years, this is the final stage and can be renamed/line below can be commented out\n",
    "  \n",
    "  \n",
    "  \n",
    "  # Convert timestamps\n",
    " # sensor_data$r_timestamp <- as.POSIXct(strptime(sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    " # sensor_data$timestamp <- NULL\n",
    " \n",
    "  sensor_data$r_timestamp <- sensor_data$timestamp\n",
    " curve_data$r_timestamp <- as.POSIXct(strptime(curve_data$timestamp,'%m/%d/%Y %H:%M', tz = \"Etc/GMT-4\"))\n",
    " curve_data$timestamp <- NULL\n",
    "\n",
    "# manual_staff_data$r_timestamp <- as.POSIXct(strptime(manual_staff_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "# # manual_staff_data$timestamp <- NULL\n",
    " \n",
    " manual_staff_data$r_timestamp <- manual_staff_data$timestamp\n",
    " manual_staff_data$stage <- manual_staff_data$`Depth.Staff Ruler Height@Wade Brook`\n",
    " \n",
    "#manual_staff_data$stage <- manual_staff_data$Staff.level..m.\n",
    "#manual_staff_data$Staff.level..m. <- NULL\n",
    "\n",
    "# Tidy up manual_staff_data for comparison\n",
    "manual_staff_data <-\n",
    "  manual_staff_data%>% \n",
    "  mutate(r_timestamp = round_date(r_timestamp, unit = \"15 mins\")) %>% \n",
    "  select(timestamp, stage) %>% \n",
    "  mutate(r_timestamp = ymd_hms(timestamp))\n",
    "\n",
    " \n",
    "# Compare sensor-derived staget to manual stage readings ----------------------------\n",
    " # Join data\n",
    " allstage <- \n",
    "   sensor_data %>% \n",
    "   select(r_timestamp, stage) %>% \n",
    "   rename(stage_sensor = stage) %>% \n",
    "   full_join(manual_staff_data %>% \n",
    "               select(r_timestamp, stage) %>% \n",
    "               rename(stage_manual = stage) %>% \n",
    "               mutate(r_timestamp = round_date(r_timestamp, unit = \"15 mins\")))\n",
    " \n",
    " # Plot\n",
    " allstage %>% \n",
    "   ggplot(aes(x = stage_manual, y = stage_sensor)) +\n",
    "   geom_point() +\n",
    "   geom_abline(slope = 1)+\n",
    "   ylim(0,1.5)+\n",
    "   xlim(0,1.5)\n",
    " \n",
    " \n",
    "# Calculate the interpolated rating curve --------------------------------------------\n",
    " # First make interpolated rating curve within measurement bounds\n",
    "  max_measured_stage <- max(curve_data$stage)\n",
    "\n",
    " # Perform the power function fit\n",
    "  fit <- nls(data = curve_data, q ~ a * stage^b,  start = list(a=1, b=1))\n",
    "  fit_coeff <- summary(fit)$coefficients\n",
    "  \n",
    "  # Pull out the coefficients\n",
    "  a <- fit_coeff[1,1]\n",
    "  b <- fit_coeff[2,1]\n",
    "  \n",
    " # Create function for curve\n",
    "  power_curve <- function(x) {a * x^b}\n",
    "  \n",
    "  sensor_data$power_q <- power_curve(sensor_data$stage)\n",
    "    \n",
    " # Find the predicted q based on measured stages and the rating curve. \n",
    "  curve_data$predicted_q <- predict(fit)\n",
    "\n",
    " # Plot to check\n",
    "  p <- ggplot(data = curve_data)\n",
    "  p <- p+ geom_point(aes(x = stage, y = q, shape = type, color = r_timestamp), size = 3)\n",
    "  p <- p+ stat_function(fun = power_curve, color = \"black\", size = 1.5)\n",
    "  p\n",
    "\n",
    "# Calculate the extrapolated rating curve ---------------------------------\n",
    "  # See survey notes for where these values came from. took averages where appropriate\n",
    "  inner_width <- 7.05\n",
    "  top_lip <- 0.2275\n",
    "  culvert_diam <- inner_width + top_lip\n",
    "  culvert_radius <- culvert_diam / 2\n",
    "  berm_height <- 1.234 # from bottom to where the currogated circular culvert begins.\n",
    "  \n",
    "  # Function to find the wetted area of the culvert above the berm\n",
    "    A_wet <- function(stage, culvert_radius = 3.63875, berm_height = 1.234, inner_width = 7.05) {\n",
    "      # Create empty result vector to populate\n",
    "      result <- numeric(length(stage))\n",
    "      # Start for loop to go through each element of stage.\n",
    "      for (i in 1:length(stage)) {\n",
    "      # See if stage is above berm height\n",
    "      if ((stage[i] - berm_height) > 0) {\n",
    "        # If it is, then find the distance above berm height (y)\n",
    "           y <- stage[i] - berm_height\n",
    "           # And calculate the wetted area below berm heigh (simple rectangle)\n",
    "           A_below_berm <- inner_width * berm_height\n",
    "      # If it's not...\n",
    "      } else { \n",
    "        # Set the distance above the berm to zero\n",
    "             y <- 0\n",
    "        # And calculate the are below based on stage (rectangular area depends on how high the stage is)\n",
    "             A_below_berm <- inner_width * stage[i]\n",
    "      } # End else statement\n",
    "      \n",
    "     # Now calculate area above berm if there is any (will be 0 if stage is below berm)\n",
    "      A_sector <- culvert_radius^2 * (pi - 2*asin(y / culvert_radius)) / 2\n",
    "      A_triangle <- y * sqrt(culvert_radius^2 - y^2)\n",
    "      semi_circ <- (1/2) * pi * culvert_radius^2\n",
    "      A_above_berm <- semi_circ - (A_sector - A_triangle)\n",
    "      \n",
    "      # Add them together for the result.\n",
    "      result[i] <- A_below_berm + A_above_berm\n",
    "      } # End for loop     \n",
    "      \n",
    "      # Return the result\n",
    "      return(result)\n",
    "    } # End function\n",
    "    \n",
    "  # Function to find hydraulic radius (wetted perimeter)\n",
    "    R_wet <- function(stage, culvert_raius = 3.63875, berm_height = 1.234, inner_width = 7.05, top_lip = 0.2275) {\n",
    "      # Create empty result vector to populate\n",
    "      result <- numeric(length(stage))\n",
    "      # Start for loop to go through each element of stage.\n",
    "      for (i in 1:length(stage)) {\n",
    "      # See if stage is above berm height\n",
    "      if ((stage[i] - berm_height) > 0) {\n",
    "        # If it is, then find the distance above berm height (y)\n",
    "        y <- stage[i] - berm_height\n",
    "        # And calculate the wetted perimeter below berm heigh (simple rectangle)\n",
    "        R_below_berm <- inner_width + (2*berm_height)\n",
    "        # If it's not...\n",
    "      } else { \n",
    "        # Set y to zero\n",
    "        y <- 0\n",
    "        # Calculate wetted perimeter based on stage\n",
    "        R_below_berm <- inner_width + (2*stage[i])\n",
    "        # Set the top_lip dimension to zero\n",
    "        top_lip <- 0\n",
    "      }\n",
    "      \n",
    "      # Now calculate wetted perimeter above berm if there is any\n",
    "      R_above_berm <- (2*top_lip) + culvert_radius * asin(y / culvert_radius)\n",
    "      # Add them together for result\n",
    "      result[i] <- R_below_berm + R_above_berm\n",
    "      } # End for loop\n",
    "      \n",
    "      return(result)\n",
    "    } # End function\n",
    "    \n",
    "    # Calculate the wetted areas and radii of the sensor and curve data measurements\n",
    "  curve_data$radius <- R_wet(curve_data$stage)\n",
    "  sensor_data$radius <- R_wet(sensor_data$stage)\n",
    "  \n",
    "  curve_data$area <- A_wet(curve_data$stage)\n",
    "  sensor_data$area <- A_wet(sensor_data$stage)\n",
    "    \n",
    "  # Determeine whether the q measurement is interpolated or extrapolated based on max stage/discharge pair\n",
    "  sensor_data[which(sensor_data$stage <= max_measured_stage), \"int_or_ext\"] <- \"interpolated\"\n",
    "  sensor_data[which(sensor_data$stage > max_measured_stage), \"int_or_ext\"] <- \"extrapolated\"\n",
    "  \n",
    "  # Slope across reach calculated by Ryan\n",
    "  slope <- 0.0244\n",
    "  \n",
    "  curve_data$back_calc_n <- curve_data$area * curve_data$radius^(2/3) * sqrt(slope) / curve_data$q\n",
    "  \n",
    "  n_rough <- 1.355\n",
    "  \n",
    "  sensor_data$mannings_q <- (1 / n_rough) * sensor_data$area * sensor_data$radius ^ (2/3) * sqrt(slope)\n",
    "  \n",
    "# Combine two methods to make best curve ----------------------------------\n",
    "\n",
    " break_point <- max_measured_stage\n",
    "  \n",
    " int <- sensor_data$stage <= break_point\n",
    " ext <- sensor_data$stage > break_point\n",
    " \n",
    "  max(sensor_data$power_q[int])\n",
    "  min(sensor_data$mannings_q[ext])\n",
    " \n",
    " sensor_data$best_q <- NA\n",
    " sensor_data$best_q[int] <- sensor_data$power_q[int]\n",
    " # Bring manning's curve down a hair so that the transition is more continuous.\n",
    " sensor_data$best_q[ext] <- sensor_data$mannings_q[ext] - 0.8*(min(sensor_data$mannings_q[ext]) - max(sensor_data$power_q[int]))\n",
    "\n",
    "  e <- ggplot(data = subset(curve_data, stage > 0.6))\n",
    "  e <- e+ geom_density(aes(x = back_calc_n))\n",
    "  e\n",
    "  \n",
    "  s <- ggplot(data = sensor_data)\n",
    "  s <- s+ geom_point(aes(x = r_timestamp, y = best_q, color = int_or_ext), size = 2)\n",
    "  s\n",
    "  \n",
    "  s <- ggplot(data = sensor_data)\n",
    "  s <- s+ geom_point(aes(x = stage, y = best_q, color = int_or_ext), size = 2)\n",
    "  s\n",
    "  \n",
    "  # Export q data\n",
    "  write.csv(sensor_data, \"wade_2023_best_q_corr_SBSS.csv\")\n",
    "\n",
    "  # -------------------------------------------------------------------------  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # ------------------------------- POTASH ----------------------------------  \n",
    "  # User inputs -------------------------------------------------------------\n",
    "  \n",
    "  # #setwd(\"/Users/erinseybold/Dropbox/R/BREE_R/NN_rating_curves\") # for MAC \n",
    "  # #2020 use wd from above-sb\n",
    "  # PB_stage_data_filename <- \"2020_Potash_Stage_corrected_sb.csv\" #raw stage data - change this to file for analysis\n",
    "  # \n",
    "  # # dist_from_hobo_to_streambed --> NO depth offset for Potash\n",
    "  # \n",
    "  # # Load data ---------------------------------------------------------------\n",
    "  # PB_sensor_data <- read.csv(PB_stage_data_filename)\n",
    "  # \n",
    "  # # Convert timestamps\n",
    "  # PB_sensor_data$r_timestamp <- as.POSIXct(strptime(PB_sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "  # PB_sensor_data$timestamp <- NULL\n",
    "  # \n",
    "  # PB_sensor_data$PB_best_q <- 3.0386*(PB_sensor_data$stage^6.5671)\n",
    "  # \n",
    "  # # Export q data\n",
    "  # write.csv(PB_sensor_data, \"potash_2020_best_q.csv\")\n",
    "  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # -------------------------------------------------------------------------  \n",
    "  # ----------------------------- HUNGERFORD --------------------------------  \n",
    "  # User inputs -------------------------------------------------------------\n",
    "  \n",
    "  # edited by SB and SS Feb-Mar 2024\n",
    "  \n",
    "  \n",
    "  # Import data\n",
    "  setwd(\"C:/Users/sshercha/OneDrive - University of Vermont/Desktop/discharge_new\")\n",
    "  \n",
    "  #### - edited by SB and SS 02292024\n",
    "  \n",
    "  source(\"AquariusR/aquariusHelperFunctions.R\", chdir = T)\n",
    "  \n",
    "  aquariusLoginWithFile(\"AquariusR/aquariusLogin\")\n",
    "  \n",
    "  \n",
    "  df1 <- getCorrectedAquariusDataSeries(\n",
    "    \"Stage.StagemHOBO@Hungerford Brook\",\n",
    "    startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "    endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "  \n",
    "  df1$timestamp <-df1$Timestamp\n",
    "  \n",
    "  df2 <- getCorrectedAquariusDataSeries(\n",
    "    \"Stage.RelDepth@Hungerford Brook\",\n",
    "    startTime = \"2020-01-01T00:00:00-05:00\",\n",
    "    endTime   = \"2023-12-31T00:00:00-05:00\")\n",
    "  \n",
    "  df2$timestamp <-df2$Timestamp\n",
    "  \n",
    "  #### - edited end ---- SB and SS 02292024\n",
    "  \n",
    "  # \n",
    "  # manual_staff_data <- read_csv(\"Wade_StaffGauge_2017-2022.csv\", col_types = cols())  %>% \n",
    "  #   mutate(r_timestamp =  mdy_hm(timestamp, tz = \"Etc/GMT+4\"))\n",
    "  \n",
    "  \n",
    "  \n",
    "  manual_staff_data <- df2 # edited by SB SS\n",
    "  \n",
    "  hobo_stage_data_filename <- df1 # edited by SB SS\n",
    "  \n",
    "  \n",
    "  # #setwd(\"/Users/erinseybold/ownCloud/BREE (2)/Watershed Data/Streams/02_site_data/discharge\") # for MAC\n",
    "  # \n",
    "  # # 2020 use wd from above-sb\n",
    "  # HF_stage_data_filename <- \"HB_Stage_2022_COMPILED.csv\" #raw stage data - change this to file for analysis\n",
    "  # \n",
    "  \n",
    "  # Load data ---------------------------------------------------------------\n",
    "  HF_sensor_data <- df1\n",
    "  \n",
    "  # Convert timestamps\n",
    "  # HF_sensor_data$r_timestamp <- as.POSIXct(strptime(HF_sensor_data$timestamp,'%m/%d/%y %H:%M', tz = \"Etc/GMT-4\"))\n",
    "  # HF_sensor_data$timestamp <- NULL\n",
    "  HF_sensor_data$r_timestamp <- HF_sensor_data$Timestamp\n",
    "  \n",
    "  \n",
    "  \n",
    "  HF_sensor_data$offset <- 0.1597 # this corrects the measured stage to the USGS stage so that the USGS rating curve can be used on NEWRnet stage time series\n",
    "  \n",
    "  #HF_sensor_data$corr_stage <- HF_sensor_data$hobo_stage-HF_sensor_data$offset # only need this for years 2014-20189\n",
    "  \n",
    "  #HF_sensor_data$corr_stage_2019 <- 0.793*HF_sensor_data$corr_stage + 0.2366 # specific to 2019 - additional offset to correct meas HOBO stage to manual measurements\n",
    "  # see file \"HfordStage_2019_COMPILED_manual stage comp\" for details on this correction (located in rating curve folder)\n",
    "  ### 2020 stage data corrected in aquarius using staff gauge readings no offset or correction needed in script-sb\n",
    "  \n",
    "  HF_sensor_data$stage <- HF_sensor_data$'Stage.StagemHOBO@Hungerford Brook' - 0.1597\n",
    "  \n",
    "  HF_sensor_data$HF_best_q <- 9.736*(HF_sensor_data$stage^2.2984)\n",
    "  \n",
    "  ggplot(HF_sensor_data, aes(r_timestamp,HF_best_q))+\n",
    "    geom_point(aes(), alpha = 0.8,  size = 2, shape = 21, colour = \"black\")+\n",
    "    ylim(0,4)\n",
    "  \n",
    "  # Export q data\n",
    "  write.csv(HF_sensor_data, \"hungerford_2023_best_q.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8b88c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
