{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c9f3290",
   "metadata": {},
   "source": [
    "## In this R notebook I use Millar et al's workflow for automatic event delineation/hysteresis index calcs using the s::can and discharge data from [Kincaid et al., 2020](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2020WR027361). \n",
    "\n",
    "## Here I adjust the Millar workflow to accept manual event delineations input and calculate event water yields.\n",
    "\n",
    "- ### Data publicly available here on HydroShare: https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "\n",
    "- ### This larger dataset includes the 2014-2015 discharge and nitrate data from Vaughan, M. (2017). Vermont NEWRnet stations: 2014-2015 high-frequency DOC, nitrate, and discharge data, HydroShare, http://www.hydroshare.org/resource/faac1672244c407e9c9c8644c8211fd6.\n",
    "\n",
    "- ### Note that there is a Hungerford data gap in 2016 to adjust this code for\n",
    "\n",
    "- ### I downloaded on 05.02.24 and put it here in this directory /home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_partition_hysteresis\n",
    "\n",
    "- ### The raw data file has discharge (q m3s), NO3, and SRP with timestamp and event start/end times for each watershed. The Millar code takes just timestamp, q, and C input csvs so I separate this raw data file into just those parameters for each site over the entire time period (>400 events from 2014 to 2018, no winter events).\n",
    "\n",
    "## I use the Kincaid 2020 events as delineated using HydRun with manual interventions.\n",
    " \n",
    " - ### Data were copied to this repo from the BREE OneDrive directory. One csv for each watershed, 2014-2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ba113013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 48.1\n",
      "[1] 0.1\n",
      "[1] 153\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# LOAD PACKAGES #\n",
    "#################\n",
    "\n",
    "library(tidyverse)\n",
    "library(viridis)\n",
    "library(dplyr)\n",
    "library(lubridate)\n",
    "library(glue)\n",
    "\n",
    "###################\n",
    "# SET DIRECTORIES #\n",
    "###################\n",
    "\n",
    "# Define the input and output directories\n",
    "\n",
    "# For Kincaid data, input and output in separate directory\n",
    "input_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/kincaid2020_hydroshare/\"\n",
    "output_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/kincaid2020_hydroshare/output/\"\n",
    "\n",
    "# functions script in main millar directory\n",
    "millar_input_dir <- \"/home/millieginty/OneDrive/git-repos/cQ_analysis/millar2021_R_separation_hysteresis/\"\n",
    "\n",
    "#####################\n",
    "# READ IN FUNCTIONS #\n",
    "#####################\n",
    "\n",
    "# 2024-07-08 MED note: I made a new version of the Millar functions script with my modifications\n",
    "source(file.path(input_dir,\"cQ_functions_MED_custom_delineations.R\"))\n",
    "\n",
    "#################\n",
    "# SET SITE INFO #\n",
    "#################\n",
    "\n",
    "# Set site name\n",
    "Site = \"Hungerford\"\n",
    "\n",
    "# Set year if doing yearly\n",
    "#Year = 2015\n",
    "\n",
    "# Set constituent\n",
    "Analyte = \"NO3\"\n",
    "\n",
    "# Set catchment area based on Site\n",
    "if (Site == \"Hungerford\") {\n",
    "  Area <- 48.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  Area <- 18.4\n",
    "} else if (Site == \"Wade\") {\n",
    "  Area <- 16.7\n",
    "} else {\n",
    "  Area <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Set stormflow thresholds \n",
    "# In this case, based on Kincaid values above in table. Can use a range in other cases (see cell below).\n",
    "if (Site == \"Hungerford\") {\n",
    "  candidateSfThresh <- 0.1\n",
    "} else if (Site == \"Potash\") {\n",
    "  candidateSfThresh <- 0.12\n",
    "} else if (Site == \"Wade\") {\n",
    "  candidateSfThresh <- 0.05\n",
    "} else {\n",
    "  candidateSfThresh <- NA  # or any default value if Site is not one of the specified values\n",
    "}\n",
    "\n",
    "# Print the Area and SFT to check\n",
    "print(Area)\n",
    "print(candidateSfThresh)\n",
    "\n",
    "############################\n",
    "# READ IN, TIDY, JOIN DATA #\n",
    "############################\n",
    "\n",
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir,\"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Rename the 'timestamp' column to 'datetime' to conform with Millar script\n",
    "names(allInputData15Min)[names(allInputData15Min) == \"timestamp\"] <- \"datetime\"\n",
    "\n",
    "# Construct the file name for event delineation based on Site definition\n",
    "events_file <- paste(\"Events\", Site, \"2014to2018.csv\", sep = \"_\")\n",
    "\n",
    "# Read in the event delineation csv file\n",
    "customEventDel <- read.csv(file.path(input_dir, \"Event_delineations_2014-2018\", events_file)) %>%\n",
    "  # Add a storm ID\n",
    "  mutate(storm_id = glue(\"storm_{row_number()}\")) %>%\n",
    "  # Select and rename columns\n",
    "  select(storm_id, rainfall.start, start = HydRun.start, end = HydRun.end) %>%\n",
    "  # Convert start and end datetimes to POSIXct\n",
    "  mutate(start = as.POSIXct(start, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"),\n",
    "         end = as.POSIXct(end, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"))\n",
    "\n",
    "# Filter the data for just the site and for the year/time range you want\n",
    "# Memory issues if you try to process all the Kincaid 2014-2018 data at once, sometimes\n",
    "# Remove rows with missing values\n",
    "Site_input <- allInputData15Min %>%\n",
    "  filter(site == Site) %>%\n",
    "  drop_na(q_cms, NO3_mgNL) %>%\n",
    "  select(datetime, q_cms, conc = NO3_mgNL) %>%\n",
    "  mutate(datetime = as.POSIXct(datetime, format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n",
    "\n",
    "# Create a list of dataframes for each storm event\n",
    "storm_data_list <- customEventDel %>%\n",
    "  rowwise() %>%\n",
    "  mutate(data = list(Site_input %>%\n",
    "    filter(datetime >= start & datetime <= end))) %>%\n",
    "  select(storm_id, data) %>%\n",
    "  group_by(storm_id) %>%\n",
    "  summarise(data = list(data))\n",
    "\n",
    "# Convert to a named list of dataframes\n",
    "storm_data_list <- setNames(storm_data_list$data, storm_data_list$storm_id)\n",
    "\n",
    "# Print the first few elements of the list to verify\n",
    "print(length(storm_data_list)) # Should be 153 storms for Hungerford in Kincaid dataset\n",
    "\n",
    "#####################\n",
    "# SET OUTPUT NAMING #\n",
    "#####################\n",
    "\n",
    "# Specify constituent in data set name\n",
    "dataSetName = paste(Site,\"_\",Analyte,\"_\",\"2014-2018\", sep=\"\")\n",
    "\n",
    "# Chose constitution for plot axes labels (NO3, TOC, or turbidity)\n",
    "constit <- Analyte\n",
    "\n",
    "Site_input$datetime <- as.POSIXct(Site_input$datetime,format(\"%Y-%m-%d %H:%M:%S\"),tz=\"EST\")\n",
    "\n",
    "# Rescale the data\n",
    "Site_input <- Site_input %>% \n",
    "  mutate(rescaled_conc = ((conc-min(conc))/(max(conc)-min(conc))*max(q_cms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bf60c",
   "metadata": {},
   "source": [
    "## Running Millar water yield calc and HI/FI calcs with custom event start and end datetimes\n",
    "\n",
    "- ### 2024-07-15 MED note: I saved cQ_functions_MED_custom_delineations from cQ_functions_MED.R\n",
    "    - #### This version allows for water and constituent event yield calcs\n",
    "- ### I wanted the `allEventDTs` dataframe created in Millar's Function 4 (`processStormEventsWithConc`) to be supplanted with an analagous dataframe that has the following for columns:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0137692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SET RDF PARAMS #\n",
    "##################\n",
    "\n",
    "# Vector containing candidate baseflow separation filter values\n",
    "candidateFilterPara <- c(0.996,0.98) # Kincaid 2020 used 0.996 for all catchments\n",
    "\n",
    "# Vector containing candidate stormflow threshold values\n",
    "#candidateSfThresh <- c(0.098,0.1,0.12) #See cell above for Kincaid comparison use case\n",
    "\n",
    "# Vector with interpolation intervals used for calculating HI\n",
    "interp <- seq(0,1,0.01)\n",
    "\n",
    "###############################\n",
    "# RUN ANALYSIS TO GET EVENTS #\n",
    "###############################\n",
    "\n",
    "batchRun1 <- batchRunBfAndEvSepForCQ(qInputs = Site_input,\n",
    "                                     bfSepPasses = 3, # orig 3\n",
    "                                     filterParam = candidateFilterPara,\n",
    "                                     sfSmoothPasses = 4, # orig 4\n",
    "                                     sfThresh = candidateSfThresh,\n",
    "                                     cInputs = Site_input,\n",
    "                                     timeStep = 15,\n",
    "                                     minDuration = 4, # Kincaid 2020 uses 4 hrs for Hungerford\n",
    "                                     maxDuration = 200,\n",
    "                                     eventInputs = customEventDel) # MED addition\n",
    "\n",
    "eventsDataAll1 <- getAllStormEvents(batchRun = batchRun1,\n",
    "                                    timestep_min = 15)\n",
    "\n",
    "batchRunFlowsLF1 <- batchRunflowCompare(qData = Site_input,\n",
    "                                         bfSepPasses = 4, # orig 4\n",
    "                                         filterPara = candidateFilterPara,\n",
    "                                         sfSmoothPasses = 4) # orig 4\n",
    "\n",
    "eventsData1 <- stormEventCalcs(batchRun = batchRun1,\n",
    "                               timestep_min = 15)\n",
    "\n",
    "eventsData1$filter_para <- as.numeric(eventsData1$filter_para)\n",
    "\n",
    "# Add water yield column (in mm) using catchment area\n",
    "eventsData1 <- eventsData1 %>%\n",
    "  mutate(\n",
    "    water_yield_mm = tot_q_m3 / (Area * 10^6) * 1000,\n",
    "  )\n",
    "\n",
    "# Add constituent yield column (in mm) using catchment area\n",
    "eventsData1 <- eventsData1 %>%\n",
    "  mutate(\n",
    "    constit_yield_mm = (tot_constit_mgN) / (Area * 10^6),\n",
    "  )\n",
    "\n",
    "stormCounts1 <- stormCounts(batchRun1)\n",
    "\n",
    "# Not dealing with HI calc in this workflow\n",
    "#hysteresisData1 <- getHysteresisIndices(batchRun = batchRun1,\n",
    "                                        #xForInterp = interp,\n",
    "                                        #eventsData = eventsData1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3afd1130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 0 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>storm_id</th><th scope=col>start</th><th scope=col>end</th><th scope=col>tot_q_m3</th><th scope=col>tot_constit_mgN</th><th scope=col>duration_hrs</th><th scope=col>intensity_m3_hr</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 0 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " storm\\_id & start & end & tot\\_q\\_m3 & tot\\_constit\\_mgN & duration\\_hrs & intensity\\_m3\\_hr\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 0 × 7\n",
       "\n",
       "| storm_id &lt;chr&gt; | start &lt;chr&gt; | end &lt;chr&gt; | tot_q_m3 &lt;dbl&gt; | tot_constit_mgN &lt;dbl&gt; | duration_hrs &lt;dbl&gt; | intensity_m3_hr &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     storm_id start end tot_q_m3 tot_constit_mgN duration_hrs intensity_m3_hr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eventInputs = storm_data_list\n",
    "\n",
    "# Define the function to calculate total discharge, duration, and discharge intensity\n",
    "stormEventCalcs <- function(timestep_min, eventInputs) {\n",
    "  \n",
    "  # Initialize the output dataframe\n",
    "  eventsData <- data.frame(\n",
    "    storm_id = character(),\n",
    "    start = character(),\n",
    "    end = character(),\n",
    "    tot_q_m3 = numeric(),\n",
    "    tot_constit_mgN = numeric(),\n",
    "    duration_hrs = numeric(),\n",
    "    intensity_m3_hr = numeric(),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  # Iterate over each storm event in the list\n",
    "  for (i in seq_along(eventInputs)) {\n",
    "    \n",
    "    # Extract the current storm event dataframe\n",
    "    storm_df <- eventInputs[[i]]\n",
    "    \n",
    "    # Check if storm_df is a dataframe and has rows\n",
    "    if (is.data.frame(storm_df) && nrow(storm_df) > 0) {\n",
    "      \n",
    "      storm_id <- names(eventInputs)[i]\n",
    "      start <- as.character(min(storm_df$datetime))\n",
    "      end <- as.character(max(storm_df$datetime))\n",
    "      tot_q_m3 <- sum(storm_df$q_cms * 60 * timestep_min)\n",
    "      tot_constit_mgN <- sum(storm_df$q_cms * storm_df$conc * 1000 * 60 * timestep_min)\n",
    "      duration_hrs <- timestep_min * nrow(storm_df) / 60\n",
    "      intensity_m3_hr <- tot_q_m3 / duration_hrs\n",
    "      \n",
    "      # Create a row for the calculated metrics\n",
    "      eventRow <- data.frame(\n",
    "        storm_id = storm_id,\n",
    "        start = start, \n",
    "        end = end, \n",
    "        tot_q_m3 = tot_q_m3,\n",
    "        tot_constit_mgN = tot_constit_mgN,\n",
    "        duration_hrs = duration_hrs,\n",
    "        intensity_m3_hr = intensity_m3_hr,\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      \n",
    "      # Append the row to the output dataframe\n",
    "      eventsData <- bind_rows(eventsData, eventRow)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(eventsData)\n",
    "}\n",
    "\n",
    "# Example usage with the list of data frames `storm_data_list` and timestep of 15 minutes\n",
    "timestep_min <- 15\n",
    "eventsData <- stormEventCalcs(timestep_min, storm_data_list)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "head(eventsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bd6d9bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 0 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>storm_id</th><th scope=col>start</th><th scope=col>end</th><th scope=col>tot_q_m3</th><th scope=col>tot_constit_mgN</th><th scope=col>duration_hrs</th><th scope=col>intensity_m3_hr</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 0 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " storm\\_id & start & end & tot\\_q\\_m3 & tot\\_constit\\_mgN & duration\\_hrs & intensity\\_m3\\_hr\\\\\n",
       " <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 0 × 7\n",
       "\n",
       "| storm_id &lt;chr&gt; | start &lt;chr&gt; | end &lt;chr&gt; | tot_q_m3 &lt;dbl&gt; | tot_constit_mgN &lt;dbl&gt; | duration_hrs &lt;dbl&gt; | intensity_m3_hr &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "\n"
      ],
      "text/plain": [
       "     storm_id start end tot_q_m3 tot_constit_mgN duration_hrs intensity_m3_hr"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "############################\n",
    "# READ IN, TIDY, JOIN DATA #\n",
    "############################\n",
    "\n",
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir,\"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Rename the 'timestamp' column to 'datetime' to conform with Millar script\n",
    "names(allInputData15Min)[names(allInputData15Min) == \"timestamp\"] <- \"datetime\"\n",
    "\n",
    "# Construct the file name for event delineation based on Site definition\n",
    "events_file <- paste(\"Events\", Site, \"2014to2018.csv\", sep = \"_\")\n",
    "\n",
    "# Read in the event delineation csv file\n",
    "customEventDel <- read.csv(file.path(input_dir, \"Event_delineations_2014-2018\", events_file)) %>%\n",
    "  # Add a storm ID\n",
    "  mutate(storm_id = glue(\"storm_{row_number()}\")) %>%\n",
    "  # Select and rename columns\n",
    "  select(storm_id, rainfall.start, start = HydRun.start, end = HydRun.end) %>%\n",
    "  # Convert start and end datetimes to POSIXct\n",
    "  mutate(start = as.POSIXct(start, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"),\n",
    "         end = as.POSIXct(end, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"))\n",
    "\n",
    "# Filter the data for just the site and for the year/time range you want\n",
    "# Memory issues if you try to process all the Kincaid 2014-2018 data at once, sometimes\n",
    "# Remove rows with missing values\n",
    "Site_input <- allInputData15Min %>%\n",
    "  filter(site == Site) %>%\n",
    "  drop_na(q_cms, NO3_mgNL) %>%\n",
    "  select(datetime, q_cms, conc = NO3_mgNL) %>%\n",
    "  mutate(datetime = as.POSIXct(datetime, format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n",
    "\n",
    "# Create a list of dataframes for each storm event\n",
    "storm_data_list <- customEventDel %>%\n",
    "  rowwise() %>%\n",
    "  mutate(data = list(Site_input %>%\n",
    "    filter(datetime >= start & datetime <= end))) %>%\n",
    "  select(storm_id, data) %>%\n",
    "  group_by(storm_id) %>%\n",
    "  summarise(data = list(data))\n",
    "\n",
    "# Convert to a named list of dataframes\n",
    "storm_data_list <- setNames(storm_data_list$data, storm_data_list$storm_id)\n",
    "\n",
    "# Print the first few elements of the list to verify\n",
    "print(length(storm_data_list)) # Should be 153 storms for Hungerford in Kincaid dataset\n",
    "\n",
    "\n",
    "#################################\n",
    "# FUNCTION TO FIND EVENT YIELDS #\n",
    "#################################\n",
    "\n",
    "eventInputs = storm_data_list\n",
    "\n",
    "# Define the function to calculate total discharge, duration, and discharge intensity\n",
    "stormEventCalcs <- function(timestep_min, eventInputs) {\n",
    "  \n",
    "  # Initialize the output dataframe\n",
    "  eventsData <- data.frame(\n",
    "    storm_id = character(),\n",
    "    start = character(),\n",
    "    end = character(),\n",
    "    tot_q_m3 = numeric(),\n",
    "    tot_constit_mgN = numeric(),\n",
    "    duration_hrs = numeric(),\n",
    "    intensity_m3_hr = numeric(),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  # Iterate over each storm event in the list\n",
    "    \n",
    "  for (i in 1:length(eventInputs)) {\n",
    "  #for (i in seq_along(eventInputs)) {\n",
    "    \n",
    "    # Extract the current storm event dataframe\n",
    "    #storm_df <- eventInputs[[i]]\n",
    "    \n",
    "    # Check if storm_df is a dataframe and has rows\n",
    "    if (is.data.frame(eventInputs[[i]]) && nrow(eventInputs[[i]]) > 0) {\n",
    "      \n",
    "      storm_id <- names(eventInputs)[i]\n",
    "      start <- as.character(min(eventInputs[[i]]$datetime))\n",
    "      end <- as.character(max(eventInputs[[i]]$datetime))\n",
    "      tot_q_m3 <- sum(eventInputs[[i]]$q_cms * 60 * timestep_min)\n",
    "      tot_constit_mgN <- sum(eventInputs[[i]]$q_cms * eventInputs[[i]]$conc * 1000 * 60 * timestep_min)\n",
    "      duration_hrs <- timestep_min * nrow(eventInputs[[i]]) / 60\n",
    "      intensity_m3_hr <- tot_q_m3 / duration_hrs\n",
    "      \n",
    "      # Create a row for the calculated metrics\n",
    "      eventRow <- data.frame(\n",
    "        storm_id = storm_id,\n",
    "        start = start, \n",
    "        end = end, \n",
    "        tot_q_m3 = tot_q_m3,\n",
    "        tot_constit_mgN = tot_constit_mgN,\n",
    "        duration_hrs = duration_hrs,\n",
    "        intensity_m3_hr = intensity_m3_hr,\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      \n",
    "      # Append the row to the output dataframe\n",
    "      eventsData <- bind_rows(eventsData, eventRow)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(eventsData)\n",
    "}\n",
    "\n",
    "# Example usage with the list of data frames `storm_data_list` and timestep of 15 minutes\n",
    "timestep_min <- 15\n",
    "eventsData <- stormEventCalcs(timestep_min, storm_data_list)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "head(eventsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a3415f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"number of storm events 153\"\n",
      "[1] TRUE\n",
      "             datetime q_cms  conc\n",
      "1 2014-06-24 23:15:00 0.117 2.362\n",
      "2 2014-06-24 23:30:00 0.123 2.350\n",
      "3 2014-06-24 23:45:00 0.135 2.350\n",
      "4 2014-06-25 00:00:00 0.135 2.351\n",
      "5 2014-06-25 00:15:00 0.135 2.342\n",
      "6 2014-06-25 00:30:00 0.135 2.330\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>storm_id</th><th scope=col>start</th><th scope=col>end</th><th scope=col>tot_q_m3</th><th scope=col>tot_constit_mgN</th><th scope=col>duration_hrs</th><th scope=col>intensity_m3_hr</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>storm_1</td><td>2014-06-24 23:15:00</td><td>2014-06-29 02:15:00</td><td>223466.4</td><td> 689120536</td><td>99.25</td><td> 2251.5506</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>storm_2</td><td>2014-10-18 13:30:00</td><td>2014-10-20 13:15:00</td><td> 26073.9</td><td>  35000768</td><td>48.00</td><td>  543.2063</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>storm_3</td><td>2017-06-25 15:45:00</td><td>2017-06-27 09:15:00</td><td>396335.7</td><td>1982821702</td><td>41.75</td><td> 9493.0707</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>storm_4</td><td>2017-06-27 14:00:00</td><td>2017-06-28 22:15:00</td><td>219233.7</td><td> 974267582</td><td>32.50</td><td> 6745.6523</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>storm_5</td><td>2017-06-29 18:15:00</td><td>2017-07-01 16:30:00</td><td>711482.4</td><td>2924380513</td><td>46.50</td><td>15300.6968</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>storm_6</td><td>2017-07-01 20:45:00</td><td>2017-07-03 05:15:00</td><td>331124.4</td><td>1289428062</td><td>32.75</td><td>10110.6687</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & storm\\_id & start & end & tot\\_q\\_m3 & tot\\_constit\\_mgN & duration\\_hrs & intensity\\_m3\\_hr\\\\\n",
       "  & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & storm\\_1 & 2014-06-24 23:15:00 & 2014-06-29 02:15:00 & 223466.4 &  689120536 & 99.25 &  2251.5506\\\\\n",
       "\t2 & storm\\_2 & 2014-10-18 13:30:00 & 2014-10-20 13:15:00 &  26073.9 &   35000768 & 48.00 &   543.2063\\\\\n",
       "\t3 & storm\\_3 & 2017-06-25 15:45:00 & 2017-06-27 09:15:00 & 396335.7 & 1982821702 & 41.75 &  9493.0707\\\\\n",
       "\t4 & storm\\_4 & 2017-06-27 14:00:00 & 2017-06-28 22:15:00 & 219233.7 &  974267582 & 32.50 &  6745.6523\\\\\n",
       "\t5 & storm\\_5 & 2017-06-29 18:15:00 & 2017-07-01 16:30:00 & 711482.4 & 2924380513 & 46.50 & 15300.6968\\\\\n",
       "\t6 & storm\\_6 & 2017-07-01 20:45:00 & 2017-07-03 05:15:00 & 331124.4 & 1289428062 & 32.75 & 10110.6687\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | storm_id &lt;chr&gt; | start &lt;chr&gt; | end &lt;chr&gt; | tot_q_m3 &lt;dbl&gt; | tot_constit_mgN &lt;dbl&gt; | duration_hrs &lt;dbl&gt; | intensity_m3_hr &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | storm_1 | 2014-06-24 23:15:00 | 2014-06-29 02:15:00 | 223466.4 |  689120536 | 99.25 |  2251.5506 |\n",
       "| 2 | storm_2 | 2014-10-18 13:30:00 | 2014-10-20 13:15:00 |  26073.9 |   35000768 | 48.00 |   543.2063 |\n",
       "| 3 | storm_3 | 2017-06-25 15:45:00 | 2017-06-27 09:15:00 | 396335.7 | 1982821702 | 41.75 |  9493.0707 |\n",
       "| 4 | storm_4 | 2017-06-27 14:00:00 | 2017-06-28 22:15:00 | 219233.7 |  974267582 | 32.50 |  6745.6523 |\n",
       "| 5 | storm_5 | 2017-06-29 18:15:00 | 2017-07-01 16:30:00 | 711482.4 | 2924380513 | 46.50 | 15300.6968 |\n",
       "| 6 | storm_6 | 2017-07-01 20:45:00 | 2017-07-03 05:15:00 | 331124.4 | 1289428062 | 32.75 | 10110.6687 |\n",
       "\n"
      ],
      "text/plain": [
       "  storm_id start               end                 tot_q_m3 tot_constit_mgN\n",
       "1 storm_1  2014-06-24 23:15:00 2014-06-29 02:15:00 223466.4  689120536     \n",
       "2 storm_2  2014-10-18 13:30:00 2014-10-20 13:15:00  26073.9   35000768     \n",
       "3 storm_3  2017-06-25 15:45:00 2017-06-27 09:15:00 396335.7 1982821702     \n",
       "4 storm_4  2017-06-27 14:00:00 2017-06-28 22:15:00 219233.7  974267582     \n",
       "5 storm_5  2017-06-29 18:15:00 2017-07-01 16:30:00 711482.4 2924380513     \n",
       "6 storm_6  2017-07-01 20:45:00 2017-07-03 05:15:00 331124.4 1289428062     \n",
       "  duration_hrs intensity_m3_hr\n",
       "1 99.25         2251.5506     \n",
       "2 48.00          543.2063     \n",
       "3 41.75         9493.0707     \n",
       "4 32.50         6745.6523     \n",
       "5 46.50        15300.6968     \n",
       "6 32.75        10110.6687     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in raw Hydroshare data csv from Kincaid et al 2020 found at https://www.hydroshare.org/resource/85fa32a11fbb49779033934a135f54ef/\n",
    "# Downloaded on 05.02.24\n",
    "allInputData15Min <- read.csv(file.path(input_dir, \"hydroshare_rawData.csv\"))\n",
    "\n",
    "# Rename the 'timestamp' column to 'datetime' to conform with Millar script\n",
    "names(allInputData15Min)[names(allInputData15Min) == \"timestamp\"] <- \"datetime\"\n",
    "\n",
    "# Construct the file name for event delineation based on Site definition\n",
    "events_file <- paste(\"Events\", Site, \"2014to2018.csv\", sep = \"_\")\n",
    "\n",
    "# Read in the event delineation csv file\n",
    "customEventDel <- read.csv(file.path(input_dir, \"Event_delineations_2014-2018\", events_file)) %>%\n",
    "  # Add a storm ID\n",
    "  mutate(storm_id = glue(\"storm_{row_number()}\")) %>%\n",
    "  # Select and rename columns\n",
    "  select(storm_id, rainfall.start, start = HydRun.start, end = HydRun.end) %>%\n",
    "  # Convert start and end datetimes to POSIXct\n",
    "  mutate(start = as.POSIXct(start, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"),\n",
    "         end = as.POSIXct(end, format = \"%m/%d/%Y %H:%M\", tz = \"EST\"))\n",
    "\n",
    "# Filter the data for just the site and for the year/time range you want\n",
    "# Memory issues if you try to process all the Kincaid 2014-2018 data at once, sometimes\n",
    "# Remove rows with missing values\n",
    "Site_input <- allInputData15Min %>%\n",
    "  filter(site == Site) %>%\n",
    "  drop_na(q_cms, NO3_mgNL) %>%\n",
    "  select(datetime, q_cms, conc = NO3_mgNL) %>%\n",
    "  mutate(datetime = as.POSIXct(datetime, format = \"%Y-%m-%d %H:%M:%S\", tz = \"EST\"))\n",
    "\n",
    "# Create a list of data frames for each storm event\n",
    "storm_data_list <- customEventDel %>%\n",
    "  rowwise() %>%\n",
    "  mutate(data = list(Site_input %>% filter(datetime >= start & datetime <= end))) %>%\n",
    "  ungroup() %>% # Ungroup to prevent grouped data issues\n",
    "  select(storm_id, data) %>%\n",
    "  group_split(storm_id) # Split by storm_id to create a list of data frames\n",
    "\n",
    "# Convert to a named list of dataframes\n",
    "storm_data_list <- setNames(lapply(storm_data_list, function(x) x$data[[1]]), customEventDel$storm_id)\n",
    "\n",
    "# Verify that the list consists of dataframes\n",
    "print(paste(\"number of storm events:\", length(storm_data_list))) # Should be 153 storms for Hungerford in Kincaid dataset\n",
    "\n",
    "# Check the structure of the first storm dataframe\n",
    "print(head(storm_data_list[[1]]))\n",
    "\n",
    "# Define the function to calculate total discharge, duration, and discharge intensity\n",
    "stormEventCalcs <- function(timestep_min, eventInputs) {\n",
    "  \n",
    "  # Initialize the output dataframe\n",
    "  eventsData <- data.frame(\n",
    "    storm_id = character(),\n",
    "    start = character(),\n",
    "    end = character(),\n",
    "    tot_q_m3 = numeric(),\n",
    "    tot_constit_mgN = numeric(),\n",
    "    duration_hrs = numeric(),\n",
    "    intensity_m3_hr = numeric(),\n",
    "    stringsAsFactors = FALSE\n",
    "  )\n",
    "  \n",
    "  # Iterate over each storm event in the list\n",
    "  for (i in seq_along(eventInputs)) {\n",
    "    \n",
    "    # Extract the current storm event dataframe\n",
    "    storm_df <- eventInputs[[i]]\n",
    "    \n",
    "    # Check if storm_df is a dataframe and has rows\n",
    "    if (is.data.frame(storm_df) && nrow(storm_df) > 0) {\n",
    "      \n",
    "      storm_id <- names(eventInputs)[i]\n",
    "      start <- as.character(min(storm_df$datetime))\n",
    "      end <- as.character(max(storm_df$datetime))\n",
    "      tot_q_m3 <- sum(storm_df$q_cms * 60 * timestep_min)\n",
    "      tot_constit_mgN <- sum(storm_df$q_cms * storm_df$conc * 1000 * 60 * timestep_min)\n",
    "      duration_hrs <- timestep_min * nrow(storm_df) / 60\n",
    "      intensity_m3_hr <- tot_q_m3 / duration_hrs\n",
    "      \n",
    "      # Create a row for the calculated metrics\n",
    "      eventRow <- data.frame(\n",
    "        storm_id = storm_id,\n",
    "        start = start, \n",
    "        end = end, \n",
    "        tot_q_m3 = tot_q_m3,\n",
    "        tot_constit_mgN = tot_constit_mgN,\n",
    "        duration_hrs = duration_hrs,\n",
    "        intensity_m3_hr = intensity_m3_hr,\n",
    "        stringsAsFactors = FALSE\n",
    "      )\n",
    "      \n",
    "      # Append the row to the output dataframe\n",
    "      eventsData <- bind_rows(eventsData, eventRow)\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return(eventsData)\n",
    "}\n",
    "\n",
    "# Example usage with the list of data frames `storm_data_list` and timestep of 15 minutes\n",
    "timestep_min <- 15\n",
    "eventsData <- stormEventCalcs(timestep_min, storm_data_list)\n",
    "\n",
    "# Look at the resulting dataframe\n",
    "head(eventsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b022633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
